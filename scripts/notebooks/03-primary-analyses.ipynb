{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Main results notebook\n",
    "\n",
    "this notebook will allow you to rerun the main statistics for the reported effects in the paper\n",
    "\n",
    "the code for this is found under src.utils.make_primary_stats, I have copied the functions here so that you may examine them before running them"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import src.utils.make_primary_stats as stats\n",
    "import src.utils.dataset_utils as ds_utils\n",
    "import pingouin as pg\n",
    "\n",
    "datadir = '/mnt/data/processed/experiment_2'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/mnt/src/utils/dataset_utils.py:584: FutureWarning: Indexing with multiple keys (implicitly converted to a tuple of keys) will be deprecated, use a list instead.\n",
      "  good_stakes.groupby([\"subid\"])[\"points\", \"rews_together\", \"rt_1\", \"rt_2\"]\n"
     ]
    }
   ],
   "source": [
    "data_dict = ds_utils.load_exp_data(datadir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def model_fitting_descriptive_stats(w1_map_df):\n",
    "    print(\"Summary stats for different components of model\")\n",
    "    print(\n",
    "        w1_map_df[\n",
    "            [\n",
    "                \"beta fit\",\n",
    "                \"alpha fit\",\n",
    "                \"lambda fit\",\n",
    "                \"w low stakes low arm fit\",\n",
    "                \"stickiness fit\",\n",
    "                \"resp stickiness fit\",\n",
    "                \"eta fit\",\n",
    "                \"kappa fit\",\n",
    "                \"LL\",\n",
    "            ]\n",
    "        ].mean()\n",
    "    )\n",
    "    print(\"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Summary stats for different components of model\n",
      "beta fit                      1.514586\n",
      "alpha fit                     0.648679\n",
      "lambda fit                    0.529495\n",
      "w low stakes low arm fit      0.571975\n",
      "stickiness fit                0.258882\n",
      "resp stickiness fit          -0.289249\n",
      "eta fit                       0.484691\n",
      "kappa fit                     0.502964\n",
      "LL                          143.861729\n",
      "dtype: float64\n",
      "\n"
     ]
    }
   ],
   "source": [
    "stats.model_fitting_descriptive_stats(data_dict['w1_map_df'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You can see the average $w$ parameter fit is 0.572"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## Behavioral indices of representational change track task structure."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "including 161 subjects\n",
      "1 sample ttest from 0 for Visual Co-occurence fit\n",
      "              T  dof alternative     p-val          CI95%   cohen-d      BF10  \\\n",
      "T-test  4.63838  160   two-sided  0.000007  [4.48, 11.12]  0.365556  1802.332   \n",
      "\n",
      "          power  \n",
      "T-test  0.99598  \n",
      "\n",
      "1 sample ttest from 0 for Direct reward association fit\n",
      "               T  dof alternative         p-val          CI95%   cohen-d  \\\n",
      "T-test  5.979339  160   two-sided  1.413007e-08  [7.15, 14.21]  0.471238   \n",
      "\n",
      "             BF10  power  \n",
      "T-test  6.929e+05    1.0  \n",
      "\n",
      "1 sample ttest from 0 for Indirect outcome-linked association fit\n",
      "               T  dof alternative         p-val          CI95%   cohen-d  \\\n",
      "T-test  5.286294  160   two-sided  4.036660e-07  [5.39, 11.82]  0.416618   \n",
      "\n",
      "           BF10     power  \n",
      "T-test  2.8e+04  0.999507  \n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(f\"including {data_dict['model_mat_fits'].subid.nunique()} subjects\")\n",
    "print(\"1 sample ttest from 0 for Visual Co-occurence fit\")\n",
    "print(pg.ttest(data_dict['model_mat_fits'][\"Visual cooccurrence\"], 0))\n",
    "print(\"\")\n",
    "print(\"1 sample ttest from 0 for Direct reward association fit\")\n",
    "print(pg.ttest(data_dict['model_mat_fits'][\"Direct item association\"], 0))\n",
    "print(\"\")\n",
    "print(\"1 sample ttest from 0 for Indirect outcome-linked association fit\")\n",
    "print(pg.ttest(data_dict['model_mat_fits'][\"Indirect item association\"], 0))\n",
    "print(\"\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## Representations of task structure correlate with task performance and model-based control.\n",
    "\n",
    "### Correlation of model matrix fits and baseline-correct points earned in the decision-making task"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def model_mat_fits_points_corr(model_mat_fits, grouped_stakes):\n",
    "    model_mat_points = pd.merge(model_mat_fits, grouped_stakes, on=\"subid\")\n",
    "    melted_mmp = model_mat_points[\n",
    "        [\n",
    "            \"subid\",\n",
    "            \"Visual cooccurrence\",\n",
    "            \"Direct item association\",\n",
    "            \"Indirect item association\",\n",
    "            \"Points earned in decision-making task\",\n",
    "            \"rt_2\",\n",
    "        ]\n",
    "    ].melt(\n",
    "        id_vars=[\"subid\", \"Points earned in decision-making task\", \"rt_2\"],\n",
    "        var_name=\"Grouping Model\",\n",
    "        value_name=r\"Model Matrix Fit ($\\bar{\\beta}$)\",\n",
    "    )\n",
    "    melted_mmp[\"model_matrix_fit\"] = melted_mmp[r\"Model Matrix Fit ($\\bar{\\beta}$)\"]\n",
    "    print(\"\")\n",
    "    print(f\"including {melted_mmp.subid.nunique()} subjects\")\n",
    "    print(\n",
    "        \"Correlation of Visual Co-occurence β with Points earned in decision-making task\"\n",
    "    )\n",
    "    print(\n",
    "        pg.corr(\n",
    "            melted_mmp[melted_mmp[\"Grouping Model\"] == \"Visual cooccurrence\"][\n",
    "                \"Points earned in decision-making task\"\n",
    "            ],\n",
    "            melted_mmp[melted_mmp[\"Grouping Model\"] == \"Visual cooccurrence\"][\n",
    "                \"model_matrix_fit\"\n",
    "            ],\n",
    "        )\n",
    "    )\n",
    "    print(\n",
    "        \"Correlation of Direct reward association β with Points earned in decision-making task\"\n",
    "    )\n",
    "    print(\n",
    "        pg.corr(\n",
    "            melted_mmp[melted_mmp[\"Grouping Model\"] == \"Direct item association\"][\n",
    "                \"Points earned in decision-making task\"\n",
    "            ],\n",
    "            melted_mmp[melted_mmp[\"Grouping Model\"] == \"Direct item association\"][\n",
    "                \"model_matrix_fit\"\n",
    "            ],\n",
    "        )\n",
    "    )\n",
    "    print(\"\")\n",
    "    print(\n",
    "        \"Correlation of Indirect outcome-linked association β with Points earned in decision-making task\"\n",
    "    )\n",
    "    print(\n",
    "        pg.corr(\n",
    "            melted_mmp[melted_mmp[\"Grouping Model\"] == \"Indirect item association\"][\n",
    "                \"Points earned in decision-making task\"\n",
    "            ],\n",
    "            melted_mmp[melted_mmp[\"Grouping Model\"] == \"Indirect item association\"][\n",
    "                \"model_matrix_fit\"\n",
    "            ],\n",
    "        )\n",
    "    )\n",
    "    print(\"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "including 161 subjects\n",
      "Correlation of Visual Co-occurence β with Points earned in decision-making task\n",
      "           n        r          CI95%     p-val   BF10     power\n",
      "pearson  161  0.00377  [-0.15, 0.16]  0.962143  0.099  0.050159\n",
      "Correlation of Direct reward association β with Points earned in decision-making task\n",
      "           n         r         CI95%     p-val     BF10     power\n",
      "pearson  161  0.324501  [0.18, 0.46]  0.000027  614.596  0.988808\n",
      "\n",
      "Correlation of Indirect outcome-linked association β with Points earned in decision-making task\n",
      "           n         r         CI95%         p-val       BF10     power\n",
      "pearson  161  0.445976  [0.31, 0.56]  3.050133e-09  3.603e+06  0.999978\n",
      "\n"
     ]
    }
   ],
   "source": [
    "stats.model_mat_fits_points_corr(data_dict['model_mat_fits'], data_dict['grouped_stakes'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def model_mat_fits_w_corr(model_mat_fits, w1_map_df):\n",
    "    melted_1w_map = w1_map_df[[\"subid\", \"w low stakes low arm fit\"]].rename(\n",
    "        columns={\"w low stakes low arm fit\": \"w fit\"}\n",
    "    )\n",
    "    model_mat_1w_map = pd.merge(model_mat_fits, melted_1w_map, on=\"subid\")\n",
    "    mm1w_melt = model_mat_1w_map.melt(\n",
    "        id_vars=[\"subid\", \"high_arm\", \"w fit\"],\n",
    "        var_name=\"Grouping Model\",\n",
    "        value_name=r\"Model Matrix Fit ($\\bar{\\beta}$)\",\n",
    "    )\n",
    "    mm1w_melt[\"model_matrix_fit\"] = mm1w_melt[r\"Model Matrix Fit ($\\bar{\\beta}$)\"]\n",
    "    print(f\"including {mm1w_melt.subid.nunique()} subjects\")\n",
    "    print(\"Correlation of Visual Co-occurrence β with w fit\")\n",
    "    print(\n",
    "        pg.corr(\n",
    "            mm1w_melt[mm1w_melt[\"Grouping Model\"] == \"Visual cooccurrence\"][\"w fit\"],\n",
    "            mm1w_melt[mm1w_melt[\"Grouping Model\"] == \"Visual cooccurrence\"][\n",
    "                \"model_matrix_fit\"\n",
    "            ],\n",
    "        )\n",
    "    )\n",
    "\n",
    "    print(\"\")\n",
    "    print(\"Correlation of Direct reward association β with w fit\")\n",
    "    print(\n",
    "        pg.corr(\n",
    "            mm1w_melt[mm1w_melt[\"Grouping Model\"] == \"Direct item association\"][\n",
    "                \"w fit\"\n",
    "            ],\n",
    "            mm1w_melt[mm1w_melt[\"Grouping Model\"] == \"Direct item association\"][\n",
    "                \"model_matrix_fit\"\n",
    "            ],\n",
    "        )\n",
    "    )\n",
    "\n",
    "    print(\"\")\n",
    "    print(\"Correlation of Indirect outcome-linked association β with w fit\")\n",
    "    print(\n",
    "        pg.corr(\n",
    "            mm1w_melt[mm1w_melt[\"Grouping Model\"] == \"Indirect item association\"][\n",
    "                \"w fit\"\n",
    "            ],\n",
    "            mm1w_melt[mm1w_melt[\"Grouping Model\"] == \"Indirect item association\"][\n",
    "                \"model_matrix_fit\"\n",
    "            ],\n",
    "        )\n",
    "    )\n",
    "\n",
    "    print(\"\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Correlation of model matrix fits and model-based control parameter "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "including 161 subjects\n",
      "Correlation of Visual Co-occurrence β with w fit\n",
      "           n         r          CI95%     p-val   BF10     power\n",
      "pearson  161 -0.140595  [-0.29, 0.01]  0.075257  0.473  0.430136\n",
      "\n",
      "Correlation of Direct reward association β with w fit\n",
      "           n         r         CI95%     p-val     BF10     power\n",
      "pearson  161  0.325581  [0.18, 0.46]  0.000025  653.687  0.989248\n",
      "\n",
      "Correlation of Indirect outcome-linked association β with w fit\n",
      "           n         r         CI95%         p-val       BF10     power\n",
      "pearson  161  0.477897  [0.35, 0.59]  1.448315e-10  6.852e+07  0.999998\n",
      "\n"
     ]
    }
   ],
   "source": [
    "stats.model_mat_fits_w_corr(data_dict['model_mat_fits'], data_dict['w1_map_df'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## Motivation affects representational change.\n",
    "\n",
    "### Stake x Arm ANOVA results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def model_based_condition_anova(w4_map_df):\n",
    "    melted_4w_map = w4_map_df[\n",
    "        [\n",
    "            \"subid\",\n",
    "            \"w low stakes low arm fit\",\n",
    "            \"w high stakes low arm fit\",\n",
    "            \"w low stakes high arm fit\",\n",
    "            \"w high stakes high arm fit\",\n",
    "        ]\n",
    "    ].melt(id_vars=[\"subid\"], var_name=\"type of\", value_name=\"w\")\n",
    "    melted_4w_map[\"arm\"] = \"high\"\n",
    "    melted_4w_map.loc[\n",
    "        np.where(melted_4w_map[\"type of\"] == \"w low stakes low arm fit\")[0], \"arm\"\n",
    "    ] = \"low\"\n",
    "    melted_4w_map.loc[\n",
    "        np.where(melted_4w_map[\"type of\"] == \"w high stakes low arm fit\")[0], \"arm\"\n",
    "    ] = \"low\"\n",
    "\n",
    "    melted_4w_map[\"stakes\"] = \"5\"\n",
    "    melted_4w_map.loc[\n",
    "        np.where(melted_4w_map[\"type of\"] == \"w low stakes low arm fit\")[0], \"stakes\"\n",
    "    ] = \"1\"\n",
    "    melted_4w_map.loc[\n",
    "        np.where(melted_4w_map[\"type of\"] == \"w low stakes high arm fit\")[0], \"stakes\"\n",
    "    ] = \"1\"\n",
    "    aov = pg.rm_anova(\n",
    "        dv=\"w\",\n",
    "        within=[\"arm\", \"stakes\"],\n",
    "        subject=\"subid\",\n",
    "        data=melted_4w_map,\n",
    "        detailed=True,\n",
    "    )\n",
    "    # Pretty printing of ANOVA summary\n",
    "    pg.print_table(aov)\n",
    "    print(\n",
    "        f\"5x w parameter is {melted_4w_map.loc[np.where(melted_4w_map['stakes'] == '5'), 'w'].mean()}\"\n",
    "    )\n",
    "    print(\n",
    "        f\"1x w parameter is {melted_4w_map.loc[np.where(melted_4w_map['stakes'] == '1'), 'w'].mean()}\"\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "=============\n",
      "ANOVA SUMMARY\n",
      "=============\n",
      "\n",
      "Source           SS    ddof1    ddof2     MS      F    p-unc    p-GG-corr    np2    eps\n",
      "------------  -----  -------  -------  -----  -----  -------  -----------  -----  -----\n",
      "arm           0.015        1      160  0.015  1.346    0.248        0.248  0.008  1.000\n",
      "stakes        0.091        1      160  0.091  7.265    0.008        0.008  0.043  1.000\n",
      "arm * stakes  0.024        1      160  0.024  1.286    0.258        0.258  0.008  1.000\n",
      "\n",
      "5x w parameter is 0.5645616887045466\n",
      "1x w parameter is 0.5408204669090588\n"
     ]
    }
   ],
   "source": [
    "stats.model_based_condition_anova(data_dict['w4_map_df'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "### 1 sample t-tests for the difference in beta values between high and low stake environment versions of the behRSA regressions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "including 161 subjects\n",
      "1 sample ttest from 0 for state1_diff\n",
      "               T  dof alternative     p-val          CI95%   cohen-d   BF10  \\\n",
      "T-test  0.452059  160   two-sided  0.651839  [-2.23, 3.56]  0.035627  0.097   \n",
      "\n",
      "           power  \n",
      "T-test  0.073435  \n",
      "\n",
      "1 sample ttest from 0 for l_diff\n",
      "               T  dof alternative    p-val          CI95%   cohen-d   BF10  \\\n",
      "T-test  1.740524  160   two-sided  0.08369  [-0.23, 3.69]  0.137173  0.384   \n",
      "\n",
      "           power  \n",
      "T-test  0.409202  \n",
      "\n",
      "1 sample ttest from 0 for o_diff\n",
      "               T  dof alternative     p-val         CI95%   cohen-d    BF10  \\\n",
      "T-test  3.222347  160   two-sided  0.001541  [1.75, 7.29]  0.253957  12.354   \n",
      "\n",
      "           power  \n",
      "T-test  0.893063  \n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(f\"including {data_dict['model_mat_hvl'].subid.nunique()} subjects\")\n",
    "print(\"1 sample ttest from 0 for state1_diff\")\n",
    "print(pg.ttest(data_dict['model_mat_hvl'][\"state1_diff\"], 0))\n",
    "print(\"\")\n",
    "print(\"1 sample ttest from 0 for l_diff\")\n",
    "print(pg.ttest(data_dict['model_mat_hvl'][\"l_diff\"], 0))\n",
    "print(\"\")\n",
    "print(\"1 sample ttest from 0 for o_diff\")\n",
    "print(pg.ttest(data_dict['model_mat_hvl'][\"o_diff\"], 0))\n",
    "print(\"\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## Memory for object-background pairings is better in higher-stakes contexts.\n",
    "\n",
    "### $d'$ differences from high and low-stakes environments"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def memory_dprime_ttest(dprime_df):\n",
    "    dprime_stat_df = dprime_df.groupby([\"subid\"]).first().reset_index()\n",
    "    print(f\"including {dprime_df.subid.nunique()} subjects\")\n",
    "    print(\"paired sample t-test between dprime mismatch for high and low arm\")\n",
    "    print(\n",
    "        pg.ttest(\n",
    "            dprime_stat_df[\"dprime_lbst_high\"],\n",
    "            dprime_stat_df[\"dprime_lbst_low\"],\n",
    "            paired=True,\n",
    "        )\n",
    "    )\n",
    "    print(\"\")\n",
    "    print(\"paired sample t-test between dprime lure for high and low arm\")\n",
    "    print(\n",
    "        pg.ttest(\n",
    "            dprime_stat_df[\"dprime_lt_high\"],\n",
    "            dprime_stat_df[\"dprime_lt_low\"],\n",
    "            paired=True,\n",
    "        )\n",
    "    )\n",
    "    print(\"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "including 161 subjects\n",
      "paired sample t-test between dprime mismatch for high and low arm\n",
      "               T  dof alternative     p-val         CI95%   cohen-d   BF10  \\\n",
      "T-test  2.289169  160   two-sided  0.023377  [0.02, 0.31]  0.167201  1.108   \n",
      "\n",
      "          power  \n",
      "T-test  0.55918  \n",
      "\n",
      "paired sample t-test between dprime lure for high and low arm\n",
      "               T  dof alternative     p-val         CI95%   cohen-d   BF10  \\\n",
      "T-test  0.816886  160   two-sided  0.415208  [-0.1, 0.25]  0.076586  0.122   \n",
      "\n",
      "           power  \n",
      "T-test  0.161824  \n",
      "\n"
     ]
    }
   ],
   "source": [
    "stats.memory_dprime_ttest(data_dict['dprime_df'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "46a92a374ab22580d330e785dc2d7bbc28533baedc701d1d9ab6ff664babcd13"
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
