{
 "cells": [
  {
   "cell_type": "markdown",
   "source": [
    "# Data cleaning notebook\n",
    "\n",
    "This notebook will allow you to run the processing code for the data presented in the paper. If you run the cells in this notebook it will overwrrite the data in interim and processed, feel free to change where the data paths are pointing or redownload the repo if you want to leave the final data alone.\n",
    "\n",
    "The code to regenerate the data are found under src.data.make_interim_dataset and src.data.make_final_dataset \n",
    "\n",
    "These scripts are not quite enough for the final statistical analysis which requires you to fit the reinforcement learning model for each participant. An example of the reinforcement learning model fit for a given subject and set of parameters is given in 02-model-fitting.ipynb notebook. Each model fit takes approximately 30 seconds and so all 209 participants will take approximately 105 minutes. \n",
    "\n",
    "To save time we use pre-run model outputs in this section."
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "The following code filters out participants based on our pre-registered criteria (e.g. non-response on 20% of trials)"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "source": [
    "!python -m src.data.make_interim_dataset \\\n",
    "-i /mnt/data/raw/experiment_2 \\\n",
    "-o /mnt/data/interim/experiment_2 \\\n",
    "-e 2 \n"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "creating clean list of subjects because one was not provided\n",
      "thresholded by dict 2\n",
      "thresholded by stakes 32\n",
      "thresholded by slider 12\n",
      "thresholded by memory 0\n",
      "making interim dataset!\n",
      "making stakes df at /mnt/data/interim/experiment_2\n",
      "making slider df and slider_hvl_df at /mnt/data/interim/experiment_2\n",
      "making memory df at /mnt/data/interim/experiment_2\n"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "Then once the model fits have been run we can run the make_final_dataset script which performs one last filtering step based on the reinforcement learning model fits"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "source": [
    "!python -m src.data.make_final_dataset \\\n",
    "-i /mnt/data/interim/experiment_2 \\\n",
    "-o /mnt/data/processed/experiment_2 \\\n",
    "-e 2 \n"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "creating clean list of subjects because one was not provided\n",
      "thresholded by model fit 2\n",
      "making final dataset!\n",
      "making stakes df at /mnt/data/processed/experiment_2\n",
      "making slider df and slider_hvl_df at /mnt/data/processed/experiment_2\n",
      "making new slider_dicts.pickle at /mnt/data/processed/experiment_2\n",
      "making w1_map_df at /mnt/data/processed/experiment_2\n",
      "making memory df at /mnt/data/processed/experiment_2\n",
      "making pca_df at /mnt/data/processed/experiment_2\n",
      "number of subjects in PCA is 161\n"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "Now the data are ready to use in the other notebooks!"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [],
   "outputs": [],
   "metadata": {}
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "46a92a374ab22580d330e785dc2d7bbc28533baedc701d1d9ab6ff664babcd13"
  },
  "kernelspec": {
   "name": "python3",
   "display_name": "Python 3.8.12 64-bit ('mb-cog-maps-paper': conda)"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}