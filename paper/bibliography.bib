
@article{behrensLearningValueInformation2007a,
  title = {Learning the Value of Information in an Uncertain World},
  author = {Behrens, Timothy E. J. and Woolrich, Mark W. and Walton, Mark E. and Rushworth, Matthew F. S.},
  year = {2007},
  month = sep,
  journal = {Nature Neuroscience},
  volume = {10},
  number = {9},
  pages = {1214--1221},
  publisher = {{Nature Publishing Group}},
  issn = {1546-1726},
  doi = {10.1038/nn1954},
  abstract = {Our decisions are guided by outcomes that are associated with decisions made in the past. However, the amount of influence each past outcome has on our next decision remains unclear. To ensure optimal decision-making, the weight given to decision outcomes should reflect their salience in predicting future outcomes, and this salience should be modulated by the volatility of the reward environment. We show that human subjects assess volatility in an optimal manner and adjust decision-making accordingly. This optimal estimate of volatility is reflected in the fMRI signal in the anterior cingulate cortex (ACC) when each trial outcome is observed. When a new piece of information is witnessed, activity levels reflect its salience for predicting future outcomes. Furthermore, variations in this ACC signal across the population predict variations in subject learning rates. Our results provide a formal account of how we weigh our different experiences in guiding our future actions.},
  copyright = {2007 Nature Publishing Group},
  langid = {english},
  keywords = {Animal Genetics and Genomics,Behavioral Sciences,Biological Techniques,Biomedicine,general,Neurobiology,Neurosciences},
  file = {/Users/abkara/Dropbox/papers/Behrens et al_2007_Learning the value of information in an uncertain world.pdf;/Users/abkara/Zotero/storage/863VUQV3/nn1954.html}
}

@article{behrensWhatCognitiveMap2018,
  title = {What {{Is}} a {{Cognitive Map}}? {{Organizing Knowledge}} for {{Flexible Behavior}}},
  shorttitle = {What {{Is}} a {{Cognitive Map}}?},
  author = {Behrens, Timothy E. J. and Muller, Timothy H. and Whittington, James C. R. and Mark, Shirley and Baram, Alon B. and Stachenfeld, Kimberly L. and {Kurth-Nelson}, Zeb},
  year = {2018},
  month = oct,
  journal = {Neuron},
  volume = {100},
  number = {2},
  pages = {490--509},
  issn = {1097-4199},
  doi = {10.1016/j.neuron.2018.10.002},
  abstract = {It is proposed that a cognitive map encoding the relationships between entities in the world supports flexible behavior, but the majority of the neural evidence for such a system comes from studies of spatial navigation. Recent work describing neuronal parallels between spatial and non-spatial behaviors has rekindled the notion of a systematic organization of knowledge across multiple domains. We review experimental evidence and theoretical frameworks that point to principles unifying these apparently disparate functions. These principles describe how to learn and use abstract, generalizable knowledge and suggest that map-like representations observed in a spatial context may be an instance of general coding mechanisms capable of organizing knowledge of all kinds. We highlight how artificial agents endowed with such principles exhibit flexible behavior and learn map-like representations observed in the brain. Finally, we speculate on how these principles may offer insight into the extreme generalizations, abstractions, and inferences that characterize human cognition.},
  langid = {english},
  pmid = {30359611},
  keywords = {Brain,Cognitive Map,Decision Making,Generalization,Hippocampal Formation,Humans,Inference,Mental Processes,Models; Neurological,Prefrontal Cortex,Reinforcement Learning,Spatial Cognition,Statistical Learning,Structure Learning},
  file = {/Users/abkara/Dropbox/papers/Behrens et al_2018_What Is a Cognitive Map.pdf}
}

@article{bellmundNavigatingCognitionSpatial2018,
  title = {Navigating Cognition: {{Spatial}} Codes for Human Thinking},
  shorttitle = {Navigating Cognition},
  author = {Bellmund, Jacob L. S. and G{\"a}rdenfors, Peter and Moser, Edvard I. and Doeller, Christian F.},
  year = {2018},
  month = nov,
  journal = {Science},
  volume = {362},
  number = {6415},
  pages = {eaat6766},
  issn = {0036-8075, 1095-9203},
  doi = {10.1126/science.aat6766},
  abstract = {The hippocampal formation has long been suggested to underlie both memory formation and spatial navigation. We discuss how neural mechanisms identified in spatial navigation research operate across information domains to support a wide spectrum of cognitive functions. In our framework, place and grid cell population codes provide a representational format to map variable dimensions of cognitive spaces. This highly dynamic mapping system enables rapid reorganization of codes through remapping between orthogonal representations across behavioral contexts, yielding a multitude of stable cognitive spaces at different resolutions and hierarchical levels. Action sequences result in trajectories through cognitive space, which can be simulated via sequential coding in the hippocampus. In this way, the spatial representational format of the hippocampal formation has the capacity to support flexible cognition and behavior.},
  langid = {english},
  file = {/Users/abkara/Zotero/storage/BF6QNA48/Bellmund et al. - 2018 - Navigating cognition Spatial codes for human thin.pdf}
}

@article{bolenzMetacontrolDecisionmakingStrategies2019,
  title = {Metacontrol of Decision-Making Strategies in Human Aging},
  author = {Bolenz, Florian and Kool, Wouter and Reiter, Andrea MF and Eppinger, Ben},
  editor = {B{\"u}chel, Christian and Kahnt, Thorsten and {Samanez-Larkin}, Greg},
  year = {2019},
  month = aug,
  journal = {eLife},
  volume = {8},
  pages = {e49154},
  publisher = {{eLife Sciences Publications, Ltd}},
  issn = {2050-084X},
  doi = {10.7554/eLife.49154},
  abstract = {Humans employ different strategies when making decisions. Previous research has reported reduced reliance on model-based strategies with aging, but it remains unclear whether this is due to cognitive or motivational factors. Moreover, it is not clear how aging affects the metacontrol of decision making, that is the dynamic adaptation of decision-making strategies to varying situational demands. In this cross-sectional study, we tested younger and older adults in a sequential decision-making task that dissociates model-free and model-based strategies. In contrast to previous research, model-based strategies led to higher payoffs. Moreover, we manipulated the costs and benefits of model-based strategies by varying reward magnitude and the stability of the task structure. Compared to younger adults, older adults showed reduced model-based decision making and less adaptation of decision-making strategies. Our findings suggest that aging affects the metacontrol of decision-making strategies and that reduced model-based strategies in older adults are due to limited cognitive abilities.},
  keywords = {decision making,lifespan development,model-based,model-free,reinforcement learning,reward},
  file = {/Users/abkara/Dropbox/papers/Bolenz et al_2019_Metacontrol of decision-making strategies in human aging.pdf}
}

@article{botvinickPlanningInference2012,
  title = {Planning as Inference},
  author = {Botvinick, Matthew and Toussaint, Marc},
  year = {2012},
  month = oct,
  journal = {Trends in Cognitive Sciences},
  volume = {16},
  number = {10},
  pages = {485--488},
  issn = {1364-6613},
  doi = {10.1016/j.tics.2012.08.006},
  abstract = {Recent developments in decision-making research are bringing the topic of planning back to center stage in cognitive science. This renewed interest reopens an old, but still unanswered question: how exactly does planning happen? What are the underlying information processing operations and how are they implemented in the brain? Although a range of interesting possibilities exists, recent work has introduced a potentially transformative new idea, according to which planning is accomplished through probabilistic inference.},
  langid = {english},
  file = {/Users/abkara/Dropbox/papers/Botvinick_Toussaint_2012_Planning as inference.pdf;/Users/abkara/Zotero/storage/QVL62HIQ/S1364661312001957.html}
}

@misc{brandleIntrinsicallyMotivatedExploration2022,
  title = {Intrinsically {{Motivated Exploration}} as {{Empowerment}}},
  author = {Br{\"a}ndle, Franziska and Stocks, Lena J. and Tenenbaum, Joshua and Gershman, Samuel J. and Schulz, Eric},
  year = {2022},
  month = jan,
  institution = {{PsyArXiv}},
  doi = {10.31234/osf.io/ybs7g},
  abstract = {Studies of human exploration frequently cast people as serendipitously stumbling upon good options. Yet these studies may not capture the richness of exploration strategies that people exhibit in more complex environments. We study human behavior in a large data set of 29,493 players of the richly-structured online game  "Little Alchemy 2''. In this game, players start with four elements, which they can combine to create up to 720 complex objects. We find that players are driven to create objects that empower them to create even more objects. We find that this drive for empowerment is eliminated when people play a version of the game that lacks recognizable semantics, indicating that they use their knowledge about the world to guide their exploration. Our results suggest that the drive for empowerment may be a potent source of intrinsic motivation in richly structured domains, particularly those that lack explicit reward signals.},
  langid = {american},
  keywords = {Cognitive Psychology,Empowerment,Exploration,Games,Intrinsic Motivation,Judgment and Decision Making,Social and Behavioral Sciences},
  file = {/Users/abkara/Dropbox/papers/Brändle et al_2022_Intrinsically Motivated Exploration as Empowerment.pdf}
}

@article{cirankaAsymmetricReinforcementLearning2022a,
  title = {Asymmetric Reinforcement Learning Facilitates Human Inference of Transitive Relations},
  author = {Ciranka, Simon and {Linde-Domingo}, Juan and Padezhki, Ivan and Wicharz, Clara and Wu, Charley M. and Spitzer, Bernhard},
  year = {2022},
  month = jan,
  journal = {Nature Human Behaviour},
  pages = {1--10},
  publisher = {{Nature Publishing Group}},
  issn = {2397-3374},
  doi = {10.1038/s41562-021-01263-w},
  abstract = {Humans and other animals are capable of inferring never-experienced relations (for example, A\,{$>$}\,C) from other relational observations (for example, A\,{$>$}\,B and B\,{$>$}\,C). The processes behind such transitive inference are subject to intense research. Here we demonstrate a new aspect of relational learning, building on previous evidence that transitive inference can be accomplished through simple reinforcement learning mechanisms. We show in simulations that inference of novel relations benefits from an asymmetric learning policy, where observers update only their belief about the winner (or loser) in a pair. Across four experiments (n\,=\,145), we find substantial empirical support for such asymmetries in inferential learning. The learning policy favoured by our simulations and experiments gives rise to a compression of values that is routinely observed in psychophysics and behavioural economics. In other words, a seemingly biased learning strategy that yields well-known cognitive distortions can be beneficial for transitive inferential judgements.},
  copyright = {2022 The Author(s)},
  langid = {english},
  keywords = {Human behaviour,Learning algorithms,Learning and memory},
  file = {/Users/abkara/Dropbox/papers/Ciranka et al_2022.pdf;/Users/abkara/Zotero/storage/E7RJCDE6/s41562-021-01263-w.html}
}

@article{collinsCognitiveControlLearning2013,
  title = {Cognitive Control over Learning: {{Creating}}, Clustering, and Generalizing Task-Set Structure},
  shorttitle = {Cognitive Control over Learning},
  author = {Collins, Anne G. E. and Frank, Michael J.},
  year = {2013},
  journal = {Psychological Review},
  volume = {120},
  number = {1},
  pages = {190--229},
  publisher = {{American Psychological Association}},
  address = {{US}},
  issn = {1939-1471(Electronic),0033-295X(Print)},
  doi = {10.1037/a0030852},
  abstract = {Learning and executive functions such as task-switching share common neural substrates, notably prefrontal cortex and basal ganglia. Understanding how they interact requires studying how cognitive control facilitates learning but also how learning provides the (potentially hidden) structure, such as abstract rules or task-sets, needed for cognitive control. We investigate this question from 3 complementary angles. First, we develop a new context-task-set (C-TS) model, inspired by nonparametric Bayesian methods, specifying how the learner might infer hidden structure (hierarchical rules) and decide to reuse or create new structure in novel situations. Second, we develop a neurobiologically explicit network model to assess mechanisms of such structured learning in hierarchical frontal cortex and basal ganglia circuits. We systematically explore the link between these modeling levels across task demands. We find that the network provides an approximate implementation of high-level C-TS computations, with specific neural mechanisms modulating distinct C-TS parameters. Third, this synergism yields predictions about the nature of human optimal and suboptimal choices and response times during learning and task-switching. In particular, the models suggest that participants spontaneously build task-set structure into a learning problem when not cued to do so, which predicts positive and negative transfer in subsequent generalization tests. We provide experimental evidence for these predictions and show that C-TS provides a good quantitative fit to human sequences of choices. These findings implicate a strong tendency to interactively engage cognitive control and learning, resulting in structured abstract representations that afford generalization opportunities and, thus, potentially long-term rather than short-term optimality. (PsycInfo Database Record (c) 2020 APA, all rights reserved)},
  keywords = {Cognitive Control,Generalization (Learning),Learning,Neural Networks,Reinforcement,Task Switching},
  file = {/Users/abkara/Dropbox/papers/Collins_Frank_2013_Cognitive control over learning.pdf;/Users/abkara/Dropbox/papers/Collins_Frank_2013_Cognitive control over learning2.pdf;/Users/abkara/Zotero/storage/6JAH59VL/Collins and Frank - 2013 - Cognitive control over learning Creating, cluster.pdf;/Users/abkara/Zotero/storage/JN6JWI76/2013-02434-002.html;/Users/abkara/Zotero/storage/KH6T4ILL/2013-02434-002.html}
}

@article{collinsCostStructureLearning2017,
  title = {The {{Cost}} of {{Structure Learning}}},
  author = {Collins, Anne G. E.},
  year = {2017},
  month = oct,
  journal = {Journal of Cognitive Neuroscience},
  volume = {29},
  number = {10},
  pages = {1646--1655},
  issn = {0898-929X, 1530-8898},
  doi = {10.1162/jocn_a_01128},
  abstract = {Abstract             Human learning is highly efficient and flexible. A key contributor to this learning flexibility is our ability to generalize new information across contexts that we know require the same behavior and to transfer rules to new contexts we encounter. To do this, we structure the information we learn and represent it hierarchically as abstract, context-dependent rules that constrain lower-level stimulus\textendash action\textendash outcome contingencies. Previous research showed that humans create such structure even when it is not needed, presumably because it usually affords long-term generalization benefits. However, computational models predict that creating structure is costly, with slower learning and slower RTs. We tested this prediction in a new behavioral experiment. Participants learned to select correct actions for four visual patterns, in a setting that either afforded (but did not promote) structure learning or enforced nonhierarchical learning, while controlling for the difficulty of the learning problem. Results replicated our previous finding that healthy young adults create structure even when unneeded and that this structure affords later generalization. Furthermore, they supported our prediction that structure learning incurred a major learning cost and that this cost was specifically tied to the effort in selecting abstract rules, leading to more errors when applying those rules. These findings confirm our theory that humans pay a high short-term cost in learning structure to enable longer-term benefits in learning flexibility.},
  langid = {english},
  file = {/Users/abkara/Dropbox/papers/Collins_2017.pdf}
}

@article{constantinescuOrganizingConceptualKnowledge2016,
  title = {Organizing Conceptual Knowledge in Humans with a Gridlike Code},
  author = {Constantinescu, Alexandra O. and O'Reilly, Jill X. and Behrens, Timothy E. J.},
  year = {2016},
  month = jun,
  journal = {Science},
  volume = {352},
  number = {6292},
  pages = {1464--1468},
  publisher = {{American Association for the Advancement of Science}},
  issn = {0036-8075, 1095-9203},
  doi = {10.1126/science.aaf0941},
  abstract = {Coding abstract concepts in the brain Grid cells are thought to provide the neuronal code that underlies spatial knowledge in the brain. Grid cells have mostly been studied in the context of path integration. However, recent theoretical studies have suggested that they may have a broader role in the organization of general knowledge. Constantinescu et al. investigated whether the neural representation of concepts follows a structure similar to the representation of space in the entorhinal cortex. Several brain regions, including the entorhinal cortex and the ventromedial prefrontal cortex, showed gridlike neural representation of conceptual space. Science, this issue p. 1464 It has been hypothesized that the brain organizes concepts into a mental map, allowing conceptual relationships to be navigated in a manner similar to that of space. Grid cells use a hexagonally symmetric code to organize spatial representations and are the likely source of a precise hexagonal symmetry in the functional magnetic resonance imaging signal. Humans navigating conceptual two-dimensional knowledge showed the same hexagonal signal in a set of brain regions markedly similar to those activated during spatial navigation. This gridlike signal is consistent across sessions acquired within an hour and more than a week apart. Our findings suggest that global relational codes may be used to organize nonspatial conceptual representations and that these codes may have a hexagonal gridlike pattern when conceptual knowledge is laid out in two continuous dimensions. Grid cells in the brain can also represent nonspatial knowledge. Grid cells in the brain can also represent nonspatial knowledge.},
  chapter = {Report},
  copyright = {Copyright \textcopyright{} 2016, American Association for the Advancement of Science},
  langid = {english},
  pmid = {27313047},
  file = {/Users/abkara/Dropbox/papers/Constantinescu et al_2016_Organizing conceptual knowledge in humans with a gridlike code.pdf;/Users/abkara/Zotero/storage/EYQY944U/1464.html}
}

@article{daddaouaIntrinsicallyMotivatedOculomotor2016,
  title = {Intrinsically Motivated Oculomotor Exploration Guided by Uncertainty Reduction and Conditioned Reinforcement in Non-Human Primates},
  author = {Daddaoua, Nabil and Lopes, Manuel and Gottlieb, Jacqueline},
  year = {2016},
  month = feb,
  journal = {Scientific Reports},
  volume = {6},
  number = {1},
  pages = {20202},
  publisher = {{Nature Publishing Group}},
  issn = {2045-2322},
  doi = {10.1038/srep20202},
  abstract = {Intelligent animals have a high degree of curiosity \textendash{} the intrinsic desire to know \textendash{} but the mechanisms of curiosity are poorly understood. A key open question pertains to the internal valuation systems that drive curiosity. What are the cognitive and emotional factors that motivate animals to seek information when this is not reinforced by instrumental rewards? Using a novel oculomotor paradigm, combined with reinforcement learning (RL) simulations, we show that monkeys are intrinsically motivated to search for and look at reward-predictive cues and that their intrinsic motivation is shaped by a desire to reduce uncertainty, a desire to obtain conditioned reinforcement from positive cues and individual variations in decision strategy and the cognitive costs of acquiring information. The results suggest that free-viewing oculomotor behavior reveals cognitive and emotional factors underlying the curiosity driven sampling of information.},
  copyright = {2016 The Author(s)},
  langid = {english},
  keywords = {Neuroscience,Oculomotor system},
  file = {/Users/abkara/Dropbox/papers/Daddaoua et al_2016.pdf;/Users/abkara/Zotero/storage/TZWPPDQQ/srep20202.html}
}

@article{dawModelBasedInfluencesHumans2011,
  title = {Model-{{Based Influences}} on {{Humans}}' {{Choices}} and {{Striatal Prediction Errors}}},
  author = {Daw, Nathaniel~D. and Gershman, Samuel~J. and Seymour, Ben and Dayan, Peter and Dolan, Raymond~J.},
  year = {2011},
  month = mar,
  journal = {Neuron},
  volume = {69},
  number = {6},
  pages = {1204--1215},
  issn = {08966273},
  doi = {10.1016/j.neuron.2011.02.027},
  langid = {english},
  file = {/Users/abkara/Dropbox/papers/Daw et al_2011_Model-Based Influences on Humans' Choices and Striatal Prediction Errors.pdf}
}

@article{dawUncertaintybasedCompetitionPrefrontal2005a,
  title = {Uncertainty-Based Competition between Prefrontal and Dorsolateral Striatal Systems for Behavioral Control},
  author = {Daw, Nathaniel D. and Niv, Yael and Dayan, Peter},
  year = {2005},
  month = dec,
  journal = {Nature Neuroscience},
  volume = {8},
  number = {12},
  pages = {1704--1711},
  issn = {1097-6256},
  doi = {10.1038/nn1560},
  abstract = {A broad range of neural and behavioral data suggests that the brain contains multiple systems for behavioral choice, including one associated with prefrontal cortex and another with dorsolateral striatum. However, such a surfeit of control raises an additional choice problem: how to arbitrate between the systems when they disagree. Here, we consider dual-action choice systems from a normative perspective, using the computational theory of reinforcement learning. We identify a key trade-off pitting computational simplicity against the flexible and statistically efficient use of experience. The trade-off is realized in a competition between the dorsolateral striatal and prefrontal systems. We suggest a Bayesian principle of arbitration between them according to uncertainty, so each controller is deployed when it should be most accurate. This provides a unifying account of a wealth of experimental evidence about the factors favoring dominance by either system.},
  langid = {english},
  pmid = {16286932},
  keywords = {Animals,Bayes Theorem,Cognition,Decision Making,Humans,Models; Neurological,Neostriatum,Neural Networks; Computer,Neural Pathways,Prefrontal Cortex,Volition}
}

@article{dayanImprovingGeneralisationTemporal,
  title = {Improving {{Generalisation}} for {{Temporal Difference Learning}}: {{The Successor Representation}}},
  author = {Dayan, Peter},
  pages = {14},
  abstract = {Estimation of returns over time, the focus of temporal difference (TD) algorithms, imposes particular constraints on good function approximators or representations. Appropriate generalisation between states is determined by how similar their successors are, and representations should follow suit. This paper shows how TD machinery can be used to learn such representations, and illustrates, using a navigation task, the appropriately distributed nature of the result.},
  langid = {english},
  file = {/Users/abkara/Dropbox/papers/Dayan_Improving Generalisation for Temporal Difference Learning.pdf}
}

@article{deleeuwJsPsychJavaScriptLibrary2015,
  title = {{{jsPsych}}: {{A JavaScript}} Library for Creating Behavioral Experiments in a {{Web}} Browser},
  shorttitle = {{{jsPsych}}},
  author = {{de Leeuw}, Joshua R.},
  year = {2015},
  month = mar,
  journal = {Behavior Research Methods},
  volume = {47},
  number = {1},
  pages = {1--12},
  issn = {1554-3528},
  doi = {10.3758/s13428-014-0458-y},
  abstract = {Online experiments are growing in popularity, and the increasing sophistication of Web technology has made it possible to run complex behavioral experiments online using only a Web browser. Unlike with offline laboratory experiments, however, few tools exist to aid in the development of browser-based experiments. This makes the process of creating an experiment slow and challenging, particularly for researchers who lack a Web development background. This article introduces jsPsych, a JavaScript library for the development of Web-based experiments. jsPsych formalizes a way of describing experiments that is much simpler than writing the entire experiment from scratch. jsPsych then executes these descriptions automatically, handling the flow from one task to another. The jsPsych library is open-source and designed to be expanded by the research community. The project is available online at www.jspsych.org.},
  langid = {english},
  file = {/Users/abkara/Zotero/storage/7CCUBXQD/de Leeuw - 2015 - jsPsych A JavaScript library for creating behavio.pdf}
}

@article{deleeuwJsPsychJavaScriptLibrary2015a,
  title = {{{jsPsych}}: {{A JavaScript}} Library for Creating Behavioral Experiments in a {{Web}} Browser},
  shorttitle = {{{jsPsych}}},
  author = {{de Leeuw}, Joshua R.},
  year = {2015},
  month = mar,
  journal = {Behavior Research Methods},
  volume = {47},
  number = {1},
  pages = {1--12},
  issn = {1554-3528},
  doi = {10.3758/s13428-014-0458-y},
  abstract = {Online experiments are growing in popularity, and the increasing sophistication of Web technology has made it possible to run complex behavioral experiments online using only a Web browser. Unlike with offline laboratory experiments, however, few tools exist to aid in the development of browser-based experiments. This makes the process of creating an experiment slow and challenging, particularly for researchers who lack a Web development background. This article introduces jsPsych, a JavaScript library for the development of Web-based experiments. jsPsych formalizes a way of describing experiments that is much simpler than writing the entire experiment from scratch. jsPsych then executes these descriptions automatically, handling the flow from one task to another. The jsPsych library is open-source and designed to be expanded by the research community. The project is available online at www.jspsych.org.},
  langid = {english},
  file = {/Users/abkara/Dropbox/papers/de Leeuw_2015_jsPsych.pdf}
}

@incollection{dimsdale-zuckerRepresentationalSimilarityAnalyses2018,
  title = {Representational {{Similarity Analyses}}},
  booktitle = {Handbook of {{Behavioral Neuroscience}}},
  author = {{Dimsdale-Zucker}, Halle R. and Ranganath, Charan},
  year = {2018},
  volume = {28},
  pages = {509--525},
  publisher = {{Elsevier}},
  doi = {10.1016/B978-0-12-812028-6.00027-6},
  isbn = {978-0-12-812028-6},
  langid = {english},
  file = {/Users/abkara/Dropbox/papers/Dimsdale-Zucker_Ranganath_2018_Representational Similarity Analyses.pdf;/Users/abkara/Zotero/storage/PCCKB4M8/Dimsdale-Zucker and Ranganath - 2018 - Representational Similarity Analyses.pdf}
}

@article{dolanGoalsHabitsBrain2013,
  title = {Goals and {{Habits}} in the {{Brain}}},
  author = {Dolan, Ray J. and Dayan, Peter},
  year = {2013},
  month = oct,
  journal = {Neuron},
  volume = {80},
  number = {2},
  pages = {312--325},
  issn = {0896-6273},
  doi = {10.1016/j.neuron.2013.09.007},
  abstract = {An enduring and richly elaborated dichotomy in cognitive neuroscience is that of reflective versus reflexive decision making and choice. Other literatures refer to the two ends of what is likely to be a spectrum with terms such as goal-directed versus habitual, model-based versus model-free or prospective versus retrospective. One of the most rigorous traditions of experimental work in the field started with studies in rodents and graduated via human versions and enrichments of those experiments to a current state in which new paradigms are probing and challenging the very heart of the distinction. We review four generations of work in this tradition and provide pointers to the forefront of the field's fifth generation.},
  langid = {english},
  file = {/Users/abkara/Dropbox/papers/Dolan_Dayan_2013_Goals and Habits in the Brain.pdf}
}

@article{dollModelbasedChoicesInvolve2015,
  title = {Model-Based Choices Involve Prospective Neural Activity},
  author = {Doll, Bradley B. and Duncan, Katherine D. and Simon, Dylan A. and Shohamy, Daphna and Daw, Nathaniel D.},
  year = {2015},
  month = may,
  journal = {Nature Neuroscience},
  volume = {18},
  number = {5},
  pages = {767--772},
  publisher = {{Nature Publishing Group}},
  issn = {1546-1726},
  doi = {10.1038/nn.3981},
  abstract = {Although it has been widely hypothesized that decisions can be guided by mental simulation of their likely consequences, there has not been direct evidence linking prospection to choices. Here, using fMRI, the authors show that neural representation of future outcomes is related to the choices that participants make.},
  copyright = {2015 Nature Publishing Group, a division of Macmillan Publishers Limited. All Rights Reserved.},
  langid = {english},
  annotation = {Bandiera\_abtest: a Cg\_type: Nature Research Journals Primary\_atype: Research Subject\_term: Decision;Learning algorithms Subject\_term\_id: decision;learning-algorithms},
  file = {/Users/abkara/Dropbox/papers/Doll et al_2015_Model-based choices involve prospective neural activity.pdf;/Users/abkara/Zotero/storage/78NKLRQJ/nn.html}
}

@article{drummondModelbasedDecisionMaking2020,
  title = {Model-Based Decision Making and Model-Free Learning},
  author = {Drummond, Nicole and Niv, Yael},
  year = {2020},
  month = aug,
  journal = {Current Biology},
  volume = {30},
  number = {15},
  pages = {R860-R865},
  issn = {09609822},
  doi = {10.1016/j.cub.2020.06.051},
  langid = {english},
  file = {/Users/abkara/Dropbox/papers/Drummond_Niv_2020_Model-based decision making and model-free learning.pdf}
}

@article{feherdasilvaHumansPrimarilyUse2020,
  title = {Humans Primarily Use Model-Based Inference in the Two-Stage Task},
  author = {{Feher da Silva}, Carolina and Hare, Todd A.},
  year = {2020},
  month = jul,
  journal = {Nature Human Behaviour},
  issn = {2397-3374},
  doi = {10.1038/s41562-020-0905-y},
  langid = {english},
  file = {/Users/abkara/Dropbox/papers/Feher da Silva_Hare_2020.pdf}
}

@article{gershmanEmpiricalPriorsReinforcement2016,
  title = {Empirical Priors for Reinforcement Learning Models},
  author = {Gershman, Samuel J.},
  year = {2016},
  month = apr,
  journal = {Journal of Mathematical Psychology},
  volume = {71},
  pages = {1--6},
  issn = {00222496},
  doi = {10.1016/j.jmp.2016.01.006},
  abstract = {Computational models of reinforcement learning have played an important role in understanding learning and decision making behavior, as well as the neural mechanisms underlying these behaviors. However, fitting the parameters of these models can be challenging: the parameters are not identifiable, estimates are unreliable, and the fitted models may not have good predictive validity. Prior distributions on the parameters can help regularize estimates and to some extent deal with these challenges, but picking a good prior is itself challenging. This paper presents empirical priors for reinforcement learning models, showing that priors estimated from a relatively large dataset are more identifiable, more reliable, and have better predictive validity compared to model-fitting with uniform priors.},
  langid = {english},
  file = {/Users/abkara/Zotero/storage/LXJYNTEC/Gershman - 2016 - Empirical priors for reinforcement learning models.pdf}
}

@article{gershmanSuccessorRepresentationIts2018,
  title = {The {{Successor Representation}}: {{Its Computational Logic}} and {{Neural Substrates}}},
  shorttitle = {The {{Successor Representation}}},
  author = {Gershman, Samuel J.},
  year = {2018},
  month = aug,
  journal = {The Journal of Neuroscience},
  volume = {38},
  number = {33},
  pages = {7193--7200},
  issn = {0270-6474, 1529-2401},
  doi = {10.1523/JNEUROSCI.0151-18.2018},
  langid = {english},
  file = {/Users/abkara/Dropbox/papers/Gershman_2018_The Successor Representation.pdf}
}

@article{gershmanSuccessorRepresentationTemporal2012,
  title = {The {{Successor Representation}} and {{Temporal Context}}},
  author = {Gershman, Samuel J. and Moore, Christopher D. and Todd, Michael T. and Norman, Kenneth A. and Sederberg, Per B.},
  year = {2012},
  month = jun,
  journal = {Neural Computation},
  volume = {24},
  number = {6},
  pages = {1553--1568},
  issn = {0899-7667, 1530-888X},
  doi = {10.1162/NECO_a_00282},
  abstract = {The successor representation was introduced into reinforcement learning by Dayan ( 1993 ) as a means of facilitating generalization between states with similar successors. Although reinforcement learning in general has been used extensively as a model of psychological and neural processes, the psychological validity of the successor representation has yet to be explored. An interesting possibility is that the successor representation can be used not only for reinforcement learning but for episodic learning as well. Our main contribution is to show that a variant of the temporal context model (TCM; Howard \& Kahana, 2002 ), an influential model of episodic memory, can be understood as directly estimating the successor representation using the temporal difference learning algorithm (Sutton \& Barto, 1998 ). This insight leads to a generalization of TCM and new experimental predictions. In addition to casting a new normative light on TCM, this equivalence suggests a previously unexplored point of contact between different learning systems.},
  langid = {english},
  file = {/Users/abkara/Dropbox/papers/Gershman et al_2012_The Successor Representation and Temporal Context.pdf}
}

@article{glascherStatesRewardsDissociable2010,
  title = {States versus {{Rewards}}: {{Dissociable Neural Prediction Error Signals Underlying Model-Based}} and {{Model-Free Reinforcement Learning}}},
  shorttitle = {States versus {{Rewards}}},
  author = {Gl{\"a}scher, Jan and Daw, Nathaniel and Dayan, Peter and O'Doherty, John P.},
  year = {2010},
  month = may,
  journal = {Neuron},
  volume = {66},
  number = {4},
  pages = {585--595},
  issn = {08966273},
  doi = {10.1016/j.neuron.2010.04.016},
  abstract = {Reinforcement learning (RL) uses sequential experience with situations (``states'') and outcomes to assess actions. Whereas model-free RL uses this experience directly, in the form of a reward prediction error (RPE), model-based RL uses it indirectly, building a model of the state transition and outcome structure of the environment, and evaluating actions by searching this model. A state prediction error (SPE) plays a central role, reporting discrepancies between the current model and the observed state transitions. Using functional magnetic resonance imaging in humans solving a probabilistic Markov decision task, we found the neural signature of an SPE in the intraparietal sulcus and lateral prefrontal cortex, in addition to the previously well-characterized RPE in the ventral striatum. This finding supports the existence of two unique forms of learning signal in humans, which may form the basis of distinct computational strategies for guiding behavior.},
  langid = {english},
  file = {/Users/abkara/Zotero/storage/QDJ6425L/Gläscher et al. - 2010 - States versus Rewards Dissociable Neural Predicti.pdf}
}

@article{gottliebAttentionLearningValue2012,
  title = {Attention, {{Learning}}, and the {{Value}} of {{Information}}},
  author = {Gottlieb, Jacqueline},
  year = {2012},
  month = oct,
  journal = {Neuron},
  volume = {76},
  number = {2},
  pages = {281--295},
  issn = {0896-6273},
  doi = {10.1016/j.neuron.2012.09.034},
  abstract = {Despite many studies on selective attention, fundamental questions remain about its nature and neural mechanisms. Here I draw from the animal and machine learning fields that describe attention as a mechanism for active learning and uncertainty reduction and explore the implications of this view for understanding visual attention and eye movement control. I propose that a closer integration of these different views has the potential greatly to expand our understanding of oculomotor control and our ability to use this system as a window into high level but poorly understood cognitive functions, including the capacity for curiosity and exploration and for inferring internal models of the external world.},
  langid = {english},
  file = {/Users/abkara/Dropbox/papers/Gottlieb_2012_Attention, Learning, and the Value of Information.pdf;/Users/abkara/Zotero/storage/QD58N9T2/S0896627312008884.html}
}

@article{grootswagersDecodingDynamicBrain2017,
  title = {Decoding {{Dynamic Brain Patterns}} from {{Evoked Responses}}: {{A Tutorial}} on {{Multivariate Pattern Analysis Applied}} to {{Time Series Neuroimaging Data}}},
  shorttitle = {Decoding {{Dynamic Brain Patterns}} from {{Evoked Responses}}},
  author = {Grootswagers, Tijl and Wardle, Susan G. and Carlson, Thomas A.},
  year = {2017},
  month = apr,
  journal = {Journal of Cognitive Neuroscience},
  volume = {29},
  number = {4},
  pages = {677--697},
  issn = {0898-929X},
  doi = {10.1162/jocn_a_01068},
  abstract = {Multivariate pattern analysis (MVPA) or brain decoding methods have become standard practice in analyzing fMRI data. Although decoding methods have been extensively applied in brain\textendash computer interfaces, these methods have only recently been applied to time series neuroimaging data such as MEG and EEG to address experimental questions in cognitive neuroscience. In a tutorial style review, we describe a broad set of options to inform future time series decoding studies from a cognitive neuroscience perspective. Using example MEG data, we illustrate the effects that different options in the decoding analysis pipeline can have on experimental results where the aim is to ``decode'' different perceptual stimuli or cognitive states over time from dynamic brain activation patterns. We show that decisions made at both preprocessing (e.g., dimensionality reduction, subsampling, trial averaging) and decoding (e.g., classifier selection, cross-validation design) stages of the analysis can significantly affect the results. In addition to standard decoding, we describe extensions to MVPA for time-varying neuroimaging data including representational similarity analysis, temporal generalization, and the interpretation of classifier weight maps. Finally, we outline important caveats in the design and interpretation of time series decoding experiments.},
  file = {/Users/abkara/Dropbox/papers/Grootswagers et al_2017_Decoding Dynamic Brain Patterns from Evoked Responses.pdf;/Users/abkara/Zotero/storage/MS9W2F9U/Decoding-Dynamic-Brain-Patterns-from-Evoked.html}
}

@article{haftingMicrostructureSpatialMap2005,
  title = {Microstructure of a Spatial Map in the Entorhinal Cortex},
  author = {Hafting, Torkel and Fyhn, Marianne and Molden, Sturla and Moser, May-Britt and Moser, Edvard I.},
  year = {2005},
  month = aug,
  journal = {Nature},
  volume = {436},
  number = {7052},
  pages = {801--806},
  publisher = {{Nature Publishing Group}},
  issn = {1476-4687},
  doi = {10.1038/nature03721},
  abstract = {The ability to find one's way depends on neural algorithms that integrate information about place, distance and direction, but the implementation of these operations in cortical microcircuits is poorly understood. Here we show that the dorsocaudal medial entorhinal cortex (dMEC) contains a directionally oriented, topographically organized neural map of the spatial environment. Its key unit is the `grid cell', which is activated whenever the animal's position coincides with any vertex of a regular grid of equilateral triangles spanning the surface of the environment. Grids of neighbouring cells share a common orientation and spacing, but their vertex locations (their phases) differ. The spacing and size of individual fields increase from dorsal to ventral dMEC. The map is anchored to external landmarks, but persists in their absence, suggesting that grid cells may be part of a generalized, path-integration-based map of the spatial environment.},
  copyright = {2005 Nature Publishing Group},
  langid = {english},
  file = {/Users/abkara/Dropbox/papers/Hafting et al_2005.pdf;/Users/abkara/Zotero/storage/WEIVRBQT/nature03721.html}
}

@article{hsuFeatureDiagnosticityAffects2014,
  title = {Feature Diagnosticity Affects Representations of Novel and Familiar Objects},
  author = {Hsu, Nina S. and Schlichting, Margaret L. and {Thompson-Schill}, Sharon L.},
  year = {2014},
  month = dec,
  journal = {Journal of cognitive neuroscience},
  volume = {26},
  number = {12},
  pages = {2735--2749},
  issn = {0898-929X},
  doi = {10.1162/jocn_a_00661},
  abstract = {Many features can describe a concept, but only some features define a concept in that they enable discrimination of items that are instances of a concept from (similar) items that are not. We refer to this property of some features as feature diagnosticity. Previous work has described the behavioral effects of feature diagnosticity, but there has been little work on explaining why and how these effects arise. In this study, we aimed to understand the impact of feature diagnosticity on concept representations across two complementary experiments. In Experiment 1, we manipulated the diagnosticity of one feature, color, for a set of novel objects that human subjects learned over the course of one week. We report behavioral and neural evidence that diagnostic features are likely to be automatically recruited during remembering. Specifically, individuals activated color-selective regions of ventral temporal cortex (specifically, left fusiform gyrus and left inferior temporal gyrus) when thinking about the novel objects, even though color information was never explicitly probed during the task. Moreover, multiple behavioral and neural measures of the effects of feature diagnosticity were correlated across subjects. In Experiment 2, we examined relative color association in familiar object categories, which varied in feature diagnosticity (fruits and vegetables, household items). Taken together, these results offer novel insights into the neural mechanisms underlying concept representations by demonstrating that automatic recruitment of diagnostic information gives rise to behavioral effects of feature diagnosticity.},
  pmcid = {PMC4216244},
  pmid = {24800630},
  file = {/Users/abkara/Dropbox/papers/Hsu et al_2014_Feature diagnosticity affects representations of novel and familiar objects.pdf}
}

@article{johnsonNeuralEnsemblesCA32007,
  title = {Neural {{Ensembles}} in {{CA3 Transiently Encode Paths Forward}} of the {{Animal}} at a {{Decision Point}}},
  author = {Johnson, Adam and Redish, A. David},
  year = {2007},
  month = nov,
  journal = {Journal of Neuroscience},
  volume = {27},
  number = {45},
  pages = {12176--12189},
  publisher = {{Society for Neuroscience}},
  issn = {0270-6474, 1529-2401},
  doi = {10.1523/JNEUROSCI.3761-07.2007},
  abstract = {Neural ensembles were recorded from the CA3 region of rats running on T-based decision tasks. Examination of neural representations of space at fast time scales revealed a transient but repeatable phenomenon as rats made a decision: the location reconstructed from the neural ensemble swept forward, first down one path and then the other. Estimated representations were coherent and preferentially swept ahead of the animal rather than behind the animal, implying it represented future possibilities rather than recently traveled paths. Similar phenomena occurred at other important decisions (such as in recovery from an error). Local field potentials from these sites contained pronounced theta and gamma frequencies, but no sharp wave frequencies. Forward-shifted spatial representations were influenced by task demands and experience. These data suggest that the hippocampus does not represent space as a passive computation, but rather that hippocampal spatial processing is an active process likely regulated by cognitive mechanisms.},
  chapter = {Articles},
  copyright = {Copyright \textcopyright{} 2007 Society for Neuroscience 0270-6474/07/2712176-14\$15.00/0},
  langid = {english},
  pmid = {17989284},
  keywords = {cognition,decision making,hippocampus,neural ensemble,place cell,vicarious trial,visual error},
  file = {/Users/abkara/Dropbox/papers/Johnson_Redish_2007.pdf;/Users/abkara/Zotero/storage/WQCPN5ZX/12176.html}
}

@article{kikumotoConjunctiveRepresentationsThat2020,
  title = {Conjunctive Representations That Integrate Stimuli, Responses, and Rules Are Critical for Action Selection},
  author = {Kikumoto, Atsushi and Mayr, Ulrich},
  year = {2020},
  month = may,
  journal = {Proceedings of the National Academy of Sciences},
  volume = {117},
  number = {19},
  pages = {10603--10608},
  publisher = {{National Academy of Sciences}},
  issn = {0027-8424, 1091-6490},
  doi = {10.1073/pnas.1922166117},
  abstract = {People can use abstract rules to flexibly configure and select actions for specific situations, yet how exactly rules shape actions toward specific sensory and/or motor requirements remains unclear. Both research from animal models and human-level theories of action control point to the role of highly integrated, conjunctive representations, sometimes referred to as event files. These representations are thought to combine rules with other, goal-relevant sensory and motor features in a nonlinear manner and represent a necessary condition for action selection. However, so far, no methods exist to track such representations in humans during action selection with adequate temporal resolution. Here, we applied time-resolved representational similarity analysis to the spectral-temporal profiles of electroencephalography signals while participants performed a cued, rule-based action selection task. In two experiments, we found that conjunctive representations were active throughout the entire selection period and were functionally dissociable from the representation of constituent features. Specifically, the strength of conjunctions was a highly robust predictor of trial-by-trial variability in response times and was selectively related to an important behavioral indicator of conjunctive representations, the so-called partial-overlap priming pattern. These results provide direct evidence for conjunctive representations as critical precursors of action selection in humans.},
  chapter = {Biological Sciences},
  copyright = {Copyright \textcopyright{} 2020 the Author(s). Published by PNAS.. https://creativecommons.org/licenses/by-nc-nd/4.0/This open access article is distributed under Creative Commons Attribution-NonCommercial-NoDerivatives License 4.0 (CC BY-NC-ND).},
  langid = {english},
  pmid = {32341161},
  keywords = {conjunctive representations,EEG decoding,rule-based action},
  file = {/Users/abkara/Dropbox/papers/Kikumoto_Mayr_2020_Conjunctive representations that integrate stimuli, responses, and rules are.pdf;/Users/abkara/Zotero/storage/HJFW4RPT/10603.html}
}

@article{koolCostBenefitArbitrationMultiple2017,
  title = {Cost-{{Benefit Arbitration Between Multiple Reinforcement-Learning Systems}}},
  author = {Kool, Wouter and Gershman, Samuel J. and Cushman, Fiery A.},
  year = {2017},
  month = sep,
  journal = {Psychological Science},
  volume = {28},
  number = {9},
  pages = {1321--1333},
  publisher = {{SAGE Publications Inc}},
  issn = {0956-7976},
  doi = {10.1177/0956797617708288},
  abstract = {Human behavior is sometimes determined by habit and other times by goal-directed planning. Modern reinforcement-learning theories formalize this distinction as a competition between a computationally cheap but inaccurate model-free system that gives rise to habits and a computationally expensive but accurate model-based system that implements planning. It is unclear, however, how people choose to allocate control between these systems. Here, we propose that arbitration occurs by comparing each system?s task-specific costs and benefits. To investigate this proposal, we conducted two experiments showing that people increase model-based control when it achieves greater accuracy than model-free control, and especially when the rewards of accurate performance are amplified. In contrast, they are insensitive to reward amplification when model-based and model-free control yield equivalent accuracy. This suggests that humans adaptively balance habitual and planned action through on-line cost-benefit analysis.},
  file = {/Users/abkara/Dropbox/papers/Kool et al_2017_Cost-Benefit Arbitration Between Multiple Reinforcement-Learning Systems.pdf;/Users/abkara/Dropbox/papers/Kool et al_2017_Cost-Benefit Arbitration Between Multiple Reinforcement-Learning Systems2.pdf}
}

@article{koolMentalLabour2018,
  title = {Mental Labour},
  author = {Kool, Wouter and Botvinick, Matthew},
  year = {2018},
  month = dec,
  journal = {Nature Human Behaviour},
  volume = {2},
  number = {12},
  pages = {899--908},
  issn = {2397-3374},
  doi = {10.1038/s41562-018-0401-9},
  langid = {english},
  file = {/Users/abkara/Dropbox/papers/Kool_Botvinick_2018_Mental labour.pdf}
}

@article{koolPlanningComplexityRegisters2018,
  title = {Planning {{Complexity Registers}} as a {{Cost}} in {{Metacontrol}}},
  author = {Kool, Wouter and Gershman, Samuel J. and Cushman, Fiery A.},
  year = {2018},
  month = oct,
  journal = {Journal of Cognitive Neuroscience},
  volume = {30},
  number = {10},
  pages = {1391--1404},
  issn = {0898-929X, 1530-8898},
  doi = {10.1162/jocn_a_01263},
  langid = {english},
  keywords = {Cognitive Effort,Decision Making},
  file = {/Users/abkara/Dropbox/papers/Kool et al_2018.pdf}
}

@article{koolWhenDoesModelBased2016,
  title = {When {{Does Model-Based Control Pay Off}}?},
  author = {Kool, Wouter and Cushman, Fiery A. and Gershman, Samuel J.},
  year = {2016},
  month = aug,
  journal = {PLOS Computational Biology},
  volume = {12},
  number = {8},
  pages = {e1005090},
  publisher = {{Public Library of Science}},
  issn = {1553-7358},
  doi = {10.1371/journal.pcbi.1005090},
  abstract = {Many accounts of decision making and reinforcement learning posit the existence of two distinct systems that control choice: a fast, automatic system and a slow, deliberative system. Recent research formalizes this distinction by mapping these systems to ``model-free'' and ``model-based'' strategies in reinforcement learning. Model-free strategies are computationally cheap, but sometimes inaccurate, because action values can be accessed by inspecting a look-up table constructed through trial-and-error. In contrast, model-based strategies compute action values through planning in a causal model of the environment, which is more accurate but also more cognitively demanding. It is assumed that this trade-off between accuracy and computational demand plays an important role in the arbitration between the two strategies, but we show that the hallmark task for dissociating model-free and model-based strategies, as well as several related variants, do not embody such a trade-off. We describe five factors that reduce the effectiveness of the model-based strategy on these tasks by reducing its accuracy in estimating reward outcomes and decreasing the importance of its choices. Based on these observations, we describe a version of the task that formally and empirically obtains an accuracy-demand trade-off between model-free and model-based strategies. Moreover, we show that human participants spontaneously increase their reliance on model-based control on this task, compared to the original paradigm. Our novel task and our computational analyses may prove important in subsequent empirical investigations of how humans balance accuracy and demand.},
  langid = {english},
  keywords = {Agent-based modeling,Behavior,Decision making,Learning,Planets,Probability distribution,Random walk,Simulation and modeling},
  file = {/Users/abkara/Dropbox/papers/Kool et al_2016_When Does Model-Based Control Pay Off.pdf;/Users/abkara/Zotero/storage/7A38C7EL/article.html}
}

@article{kriegeskorteRepresentationalSimilarityAnalysis2008,
  title = {Representational Similarity Analysis - Connecting the Branches of Systems Neuroscience},
  author = {Kriegeskorte, Nikolaus and Mur, Marieke and Bandettini, Peter},
  year = {2008},
  journal = {Frontiers in Systems Neuroscience},
  volume = {2},
  pages = {4},
  issn = {1662-5137},
  doi = {10.3389/neuro.06.004.2008},
  abstract = {A fundamental challenge for systems neuroscience is to quantitatively relate its three major branches of research: brain-activity measurement, behavioral measurement, and computational modeling. Using measured brain-activity patterns to evaluate computational network models is complicated by the need to define the correspondency between the units of the model and the channels of the brain-activity data, e.g., single-cell recordings or voxels from functional magnetic resonance imaging (fMRI). Similar correspondency problems complicate relating activity patterns between different modalities of brain-activity measurement (e.g., fMRI and invasive or scalp electrophysiology), and between subjects and species. In order to bridge these divides, we suggest abstracting from the activity patterns themselves and computing representational dissimilarity matrices (RDMs), which characterize the information carried by a given representation in a brain or model. Building on a rich psychological and mathematical literature on similarity analysis, we propose a new experimental and data-analytical framework called representational similarity analysis (RSA), in which multi-channel measures of neural activity are quantitatively related to each other and to computational theory and behavior by comparing RDMs. We demonstrate RSA by relating representations of visual objects as measured with fMRI in early visual cortex and the fusiform face area to computational models spanning a wide range of complexities. The RDMs are simultaneously related via second-level application of multidimensional scaling and tested using randomization and bootstrap techniques. We discuss the broad potential of RSA, including novel approaches to experimental design, and argue that these ideas, which have deep roots in psychology and neuroscience, will allow the integrated quantitative analysis of data from all three branches, thus contributing to a more unified systems neuroscience.},
  file = {/Users/abkara/Dropbox/papers/Kriegeskorte et al_2008_Representational similarity analysis - connecting the branches of systems.pdf}
}

@article{mattarPlanningBrain2022,
  title = {Planning in the Brain},
  author = {Mattar, Marcelo G. and Lengyel, M{\'a}t{\'e}},
  year = {2022},
  month = mar,
  journal = {Neuron},
  volume = {110},
  number = {6},
  pages = {914--934},
  issn = {08966273},
  doi = {10.1016/j.neuron.2021.12.018},
  abstract = {Recent breakthroughs in artificial intelligence (AI) have enabled machines to plan in tasks previously thought to be uniquely human. Meanwhile, the planning algorithms implemented by the brain itself remain largely unknown. Here, we review neural and behavioral data in sequential decision-making tasks that elucidate the ways in which the brain does\textemdash and does not\textemdash plan. To systematically review available biological data, we create a taxonomy of planning algorithms by summarizing the relevant design choices for such algorithms in AI. Across species, recording techniques, and task paradigms, we find converging evidence that the brain represents future states consistent with a class of planning algorithms within our taxonomy\textemdash focused, depthlimited, and serial. However, we argue that current data are insufficient for addressing more detailed algorithmic questions. We propose a new approach leveraging AI advances to drive experiments that can adjudicate between competing candidate algorithms.},
  langid = {english},
  file = {/Users/abkara/Zotero/storage/DX626REH/Mattar and Lengyel - 2022 - Planning in the brain.pdf}
}

@article{momennejadLearningStructuresPredictive2020,
  ids = {momennejadLearningStructuresPredictive},
  title = {Learning {{Structures}}: {{Predictive Representations}}, {{Replay}}, and {{Generalization}}},
  shorttitle = {Learning {{Structures}}},
  author = {Momennejad, Ida},
  year = {2020},
  month = apr,
  journal = {Current Opinion in Behavioral Sciences},
  volume = {32},
  pages = {155--166},
  issn = {23521546},
  doi = {10.1016/j.cobeha.2020.02.017},
  langid = {english},
  file = {/home/abkara/Dropbox/papers/momennejad_2020.pdf;/home/abkara/Dropbox/papers/momennejad_psyarxiv_2020.pdf;/Users/abkara/Dropbox/papers/Momennejad_2020_Learning Structures.pdf}
}

@article{momennejadSuccessorRepresentationHuman2017,
  title = {The Successor Representation in Human Reinforcement Learning},
  author = {Momennejad, I. and Russek, E. M. and Cheong, J. H. and Botvinick, M. M. and Daw, N. D. and Gershman, S. J.},
  year = {2017},
  month = sep,
  journal = {Nature Human Behaviour},
  volume = {1},
  number = {9},
  pages = {680--692},
  publisher = {{Nature Publishing Group}},
  issn = {2397-3374},
  doi = {10.1038/s41562-017-0180-8},
  abstract = {Theories of reward learning in neuroscience have focused on two families of algorithms thought to capture deliberative versus habitual choice. `Model-based' algorithms compute the value of candidate actions from scratch, whereas `model-free' algorithms make choice more efficient but less flexible by storing pre-computed action values. We examine an intermediate algorithmic family, the successor representation, which balances flexibility and efficiency by storing partially computed action values: predictions about future events. These pre-computation strategies differ in how they update their choices following changes in a task. The successor representation's reliance on stored predictions about future states predicts a unique signature of insensitivity to changes in the task's sequence of events, but flexible adjustment following changes to rewards. We provide evidence for such differential sensitivity in two behavioural studies with humans. These results suggest that the successor representation is a computational substrate for semi-flexible choice in humans, introducing a subtler, more cognitive notion of habit.},
  copyright = {2017 The Author(s)},
  langid = {english},
  annotation = {Bandiera\_abtest: a Cg\_type: Nature Research Journals Primary\_atype: Research Subject\_term: Extinction;Human behaviour Subject\_term\_id: extinction;human-behaviour},
  file = {/Users/abkara/Dropbox/papers/Momennejad et al_2017_The successor representation in human reinforcement learning.pdf;/Users/abkara/Zotero/storage/CRNAHPNE/s41562-017-0180-8.html}
}

@article{musaShallowCognitiveMap2022,
  title = {The Shallow Cognitive Map Hypothesis: {{A}} Hippocampal Framework for Thought Disorder in Schizophrenia},
  shorttitle = {The Shallow Cognitive Map Hypothesis},
  author = {Musa, Ayesha and Khan, Safia and Mujahid, Minahil and {El-Gaby}, Mohamady},
  year = {2022},
  month = apr,
  journal = {Schizophrenia},
  volume = {8},
  number = {1},
  pages = {1--11},
  publisher = {{Nature Publishing Group}},
  issn = {2334-265X},
  doi = {10.1038/s41537-022-00247-7},
  abstract = {Memories are not formed in isolation. They are associated and organized into relational knowledge structures that allow coherent thought. Failure to express such coherent thought is a key hallmark of Schizophrenia. Here we explore the hypothesis that thought disorder arises from disorganized Hippocampal cognitive maps. In doing so, we combine insights from two key lines of investigation, one concerning the neural signatures of cognitive mapping, and another that seeks to understand lower-level cellular mechanisms of cognition within a dynamical systems framework. Specifically, we propose that multiple distinct pathological pathways converge on the shallowing of Hippocampal attractors, giving rise to disorganized Hippocampal cognitive maps and driving conceptual disorganization. We discuss the available evidence at the computational, behavioural, network, and cellular levels. We also outline testable predictions from this framework, including how it could unify major chemical and psychological theories of schizophrenia and how it can provide a rationale for understanding the aetiology and treatment of the disease.},
  copyright = {2022 The Author(s)},
  langid = {english},
  keywords = {Neural circuits,Psychosis,Schizophrenia},
  file = {/Users/abkara/Dropbox/papers/Musa et al_2022_The shallow cognitive map hypothesis.pdf;/Users/abkara/Zotero/storage/W7XXUVKC/s41537-022-00247-7.html}
}

@article{navawongseDistinctPathwaysRuleBased2013,
  title = {Distinct {{Pathways}} for {{Rule-Based Retrieval}} and {{Spatial Mapping}} of {{Memory Representations}} in {{Hippocampal Neurons}}},
  author = {Navawongse, Rapeechai and Eichenbaum, Howard},
  year = {2013},
  month = jan,
  journal = {Journal of Neuroscience},
  volume = {33},
  number = {3},
  pages = {1002--1013},
  publisher = {{Society for Neuroscience}},
  issn = {0270-6474, 1529-2401},
  doi = {10.1523/JNEUROSCI.3891-12.2013},
  abstract = {Hippocampal neurons encode events within the context in which they occurred, a fundamental feature of episodic memory. Here we explored the sources of event and context information represented by hippocampal neurons during the retrieval of object associations in rats. Temporary inactivation of the medial prefrontal cortex differentially reduced the selectivity of rule-based object associations represented by hippocampal neuronal firing patterns but did not affect spatial firing patterns. In contrast, inactivation of the medial entorhinal cortex resulted in a pervasive reorganization of hippocampal mappings of spatial context and events. These results suggest distinct and cooperative prefrontal and medial temporal mechanisms in memory representation.},
  chapter = {Articles},
  copyright = {Copyright \textcopyright{} 2013 the authors 0270-6474/13/331002-12\$15.00/0},
  langid = {english},
  pmid = {23325238},
  file = {/Users/abkara/Dropbox/papers/Navawongse_Eichenbaum_2013_Distinct Pathways for Rule-Based Retrieval and Spatial Mapping of Memory.pdf;/Users/abkara/Zotero/storage/8EBR475M/1002.html}
}

@book{okeefeHippocampusCognitiveMap1978,
  title = {The {{Hippocampus}} as a {{Cognitive Map}}},
  author = {O'Keefe, J. and Nadel, L.},
  year = {1978},
  publisher = {{Clarendon Press}},
  isbn = {978-0-19-857206-0},
  lccn = {lc77030572},
  keywords = {Cognition,Hippocampus (Brain),Memory},
  file = {/Users/abkara/Zotero/storage/4S7986AV/O'Keefe and Nadel - 1978 - The hippocampus as a cognitive map.pdf}
}

@article{parkInferencesMultidimensionalSocial2021,
  title = {Inferences on a Multidimensional Social Hierarchy Use a Grid-like Code},
  author = {Park, Seongmin A. and Miller, Douglas S. and Boorman, Erie D.},
  year = {2021},
  month = sep,
  journal = {Nature Neuroscience},
  volume = {24},
  number = {9},
  pages = {1292--1301},
  publisher = {{Nature Publishing Group}},
  issn = {1546-1726},
  doi = {10.1038/s41593-021-00916-3},
  abstract = {Generalizing experiences to guide decision-making in novel situations is a hallmark of flexible behavior. Cognitive maps of an environment or task can theoretically afford such flexibility, but direct evidence has proven elusive. In this study, we found that discretely sampled abstract relationships between entities in an unseen two-dimensional social hierarchy are reconstructed into a unitary two-dimensional cognitive map in the hippocampus and entorhinal cortex. We further show that humans use a grid-like code in entorhinal cortex and medial prefrontal cortex for inferred direct trajectories between entities in the reconstructed abstract space during discrete decisions. These grid-like representations in the entorhinal cortex are associated with decision value computations in the medial prefrontal cortex and temporoparietal junction. Collectively, these findings show that grid-like representations are used by the human brain to infer novel solutions, even in abstract and discrete problems, and suggest a general mechanism underpinning flexible decision-making and generalization. Cognitive maps are theorized to enable generalizing experiences in new situations. Park et al. show that non-spatial experiences sampled piecemeal are integrated into a two-dimensional cognitive map of social hierarchy, and a grid code is used for novel inferences.},
  copyright = {2021 The Author(s), under exclusive licence to Springer Nature America, Inc.},
  langid = {english},
  annotation = {Primary\_atype: Research Subject\_term: Decision;Social neuroscience Subject\_term\_id: decision;social-neuroscience},
  file = {/Users/abkara/Dropbox/papers/Park et al_2021.pdf;/Users/abkara/Zotero/storage/SP9A953I/s41593-021-00916-3.html}
}

@article{parkMapMakingConstructing2020,
  title = {Map {{Making}}: {{Constructing}}, {{Combining}}, and {{Inferring}} on {{Abstract Cognitive Maps}}},
  shorttitle = {Map {{Making}}},
  author = {Park, Seongmin A. and Miller, Douglas S. and Nili, Hamed and Ranganath, Charan and Boorman, Erie D.},
  year = {2020},
  month = jul,
  journal = {Neuron},
  pages = {S0896627320304840},
  issn = {08966273},
  doi = {10.1016/j.neuron.2020.06.030},
  abstract = {Cognitive maps enable efficient inferences from limited experience that can guide novel decisions. We tested whether the hippocampus (HC), entorhinal cortex (EC), and ventromedial prefrontal cortex (vmPFC)/medial orbitofrontal cortex (mOFC) organize abstract and discrete relational information into a cognitive map to guide novel inferences. Subjects learned the status of people in two unseen 2D social hierarchies, with each dimension learned on a separate day. Although one dimension was behaviorally relevant, multivariate activity patterns in HC, EC, and vmPFC/mOFC were linearly related to the Euclidean distance between people in the mentally reconstructed 2D space. Hubs created unique comparisons between the hierarchies, enabling inferences between novel pairs. We found that both behavior and neural activity in EC and vmPFC/mOFC reflected the Euclidean distance to the retrieved hub, which was reinstated in HC. These findings reveal how abstract and discrete relational structures are represented, are combined, and enable novel inferences in the human brain.},
  langid = {english},
  file = {/home/abkara/Dropbox/papers/Park-2020-Map-making-constructing-combining.pdf;/Users/abkara/Dropbox/papers/Park et al_2020_Map Making.pdf}
}

@article{patilReasoningSupportsUtilitarian2021,
  title = {Reasoning Supports Utilitarian Resolutions to Moral Dilemmas across Diverse Measures},
  author = {Patil, Indrajeet and Zucchelli, Micaela Maria and Kool, Wouter and Campbell, Stephanie and Fornasier, Federico and Cal{\`o}, Marta and Silani, Giorgia and Cikara, Mina and Cushman, Fiery},
  year = {2021},
  month = feb,
  journal = {Journal of Personality and Social Psychology},
  volume = {120},
  number = {2},
  pages = {443--460},
  publisher = {{American Psychological Association}},
  issn = {0022-3514},
  doi = {10.1037/pspp0000281},
  abstract = {Sacrificial moral dilemmas elicit a strong conflict between the motive to not personally harm someone and the competing motive to achieving the greater good, which is often described as the 'utilitarian' response. Some prior research suggests that reasoning abilities and deliberative cognitive style are associated with endorsement of utilitarian solutions, but, as has more recently been emphasized, both conceptual and methodological issues leave open the possibility that utilitarian responses are due instead to a reduced emotional response to harm. Across 8 studies, using self-report, behavioral performance, and neuroanatomical measures, we show that individual differences in reasoning ability and cognitive style of thinking are positively associated with a preference for utilitarian solutions, but bear no relationship to harm-relevant concerns. These findings support the dual-process model of moral decision making and highlight the utility of process dissociation methods. (PsycInfo Database Record (c) 2021 APA, all rights reserved)},
  keywords = {Cognitive Style,Dissociation,Dual Process Models,dual-process model,moral dilemmas,Morality,Motivation,process dissociation,reasoning,Reasoning,Social Dilemma,utilitarianism},
  file = {/Users/abkara/Dropbox/papers/Patil et al_2021_Reasoning supports utilitarian resolutions to moral dilemmas across diverse.pdf}
}

@article{patzeltIncentivesBoostModelBased2019,
  title = {Incentives {{Boost Model-Based Control Across}} a {{Range}} of {{Severity}} on {{Several Psychiatric Constructs}}},
  author = {Patzelt, Edward H. and Kool, Wouter and Millner, Alexander J. and Gershman, Samuel J.},
  year = {2019},
  month = mar,
  journal = {Biological Psychiatry},
  volume = {85},
  number = {5},
  pages = {425--433},
  issn = {00063223},
  doi = {10.1016/j.biopsych.2018.06.018},
  abstract = {BACKGROUND: Human decision making exhibits a mixture of model-based and model-free control. Recent evidence indicates that arbitration between these two modes of control (``metacontrol'') is based on their relative costs and benefits. While model-based control may increase accuracy, it requires greater computational resources, so people invoke model-based control only when potential rewards exceed those of model-free control. We used a sequential decision task, while concurrently manipulating performance incentives, to ask if symptoms and traits of psychopathology decrease or increase model-based control in response to incentives. METHODS: We recruited a nonpatient population of 839 online participants using Amazon Mechanical Turk who completed transdiagnostic self-report measures encompassing symptoms, traits, and factors. We fit a dual-controller reinforcement learning model and obtained a computational measure of model-based control separately for small incentives and large incentives. RESULTS: None of the constructs were related to a failure of large incentives to boost model-based control. In fact, for the sensation seeking trait and anxious-depression factor, higher scores were associated with a larger incentive effect, whereby greater levels of these constructs were associated with larger increases in model-based control. Many constructs showed decreases in model-based control as a function of severity, but a social withdrawal factor was positively correlated; alcohol use and social anxiety were unrelated to model-based control. CONCLUSIONS: Our results demonstrate that model-based control can reliably be improved independent of construct severity for most measures. This suggests that incentives may be a useful intervention for boosting model-based control across a range of symptom and trait severity.},
  langid = {english},
  file = {/Users/abkara/Dropbox/papers/Patzelt et al_2019.pdf}
}

@article{pedregosaScikitlearnMachineLearning2018,
  title = {Scikit-Learn: {{Machine Learning}} in {{Python}}},
  shorttitle = {Scikit-Learn},
  author = {Pedregosa, Fabian and Varoquaux, Ga{\"e}l and Gramfort, Alexandre and Michel, Vincent and Thirion, Bertrand and Grisel, Olivier and Blondel, Mathieu and M{\"u}ller, Andreas and Nothman, Joel and Louppe, Gilles and Prettenhofer, Peter and Weiss, Ron and Dubourg, Vincent and Vanderplas, Jake and Passos, Alexandre and Cournapeau, David and Brucher, Matthieu and Perrot, Matthieu and Duchesnay, {\'E}douard},
  year = {2018},
  month = jun,
  journal = {arXiv:1201.0490 [cs]},
  eprint = {1201.0490},
  eprinttype = {arxiv},
  primaryclass = {cs},
  abstract = {Scikit-learn is a Python module integrating a wide range of state-of-the-art machine learning algorithms for medium-scale supervised and unsupervised problems. This package focuses on bringing machine learning to non-specialists using a general-purpose high-level language. Emphasis is put on ease of use, performance, documentation, and API consistency. It has minimal dependencies and is distributed under the simplified BSD license, encouraging its use in both academic and commercial settings. Source code, binaries, and documentation can be downloaded from http://scikit-learn.org.},
  archiveprefix = {arXiv},
  keywords = {Computer Science - Machine Learning,Computer Science - Mathematical Software},
  file = {/Users/abkara/Dropbox/papers/Pedregosa et al_2018_Scikit-learn.pdf;/Users/abkara/Zotero/storage/5CIB39F2/1201.html}
}

@article{rmusHumansCanNavigate2022,
  title = {Humans Can Navigate Complex Graph Structures Acquired during Latent Learning},
  author = {Rmus, Milena and Ritz, Harrison and Hunter, Lindsay E. and Bornstein, Aaron M. and Shenhav, Amitai},
  year = {2022},
  month = aug,
  journal = {Cognition},
  volume = {225},
  pages = {105103},
  issn = {00100277},
  doi = {10.1016/j.cognition.2022.105103},
  abstract = {Humans appear to represent many forms of knowledge in associative networks whose nodes are multiply connected, including sensory, spatial, and semantic. Recent work has shown that explicitly augmenting artificial agents with such graph-structured representations endows them with more human-like capabilities of compo\- sitionality and transfer learning. An open question is how humans acquire these representations. Previously, it has been shown that humans can learn to navigate graph-structured conceptual spaces on the basis of direct experience with trajectories that intentionally draw the network contours (Schapiro, Kustner, \& TurkBrowne, 2012; Schapiro, Turk-Browne, Botvinick, \& Norman, 2016), or through direct experience with rewards that covary with the underlying associative dis\- tance (Wu, Schulz, Speekenbrink, Nelson, \& Meder, 2018). Here, we provide initial evidence that this capability is more general, extending to learning to reason about shortest-path distances across a graph structure acquired across disjoint experiences with randomized edges of the graph - a form of latent learning. In other words, we show that humans can infer graph structures, assembling them from disordered experiences. We further show that the degree to which individuals learn to reason correctly and with reference to the structure of the graph corresponds to their propensity, in a separate task, to use model-based reinforcement learning to achieve rewards. This connection suggests that the correct acquisition of graph-structured relationships is a central ability underlying forward planning and reasoning, and may be a core computation across the many domains in which graph-based reasoning is advantageous.},
  langid = {english},
  file = {/Users/abkara/Zotero/storage/ENG28T85/Rmus et al. - 2022 - Humans can navigate complex graph structures acqui.pdf}
}

@misc{russekNeuralEvidenceSuccessor2021,
  title = {Neural Evidence for the Successor Representation in Choice Evaluation},
  author = {Russek, Evan M. and Momennejad, Ida and Botvinick, Matthew M. and Gershman, Samuel J. and Daw, Nathaniel D.},
  year = {2021},
  month = aug,
  pages = {2021.08.29.458114},
  institution = {{Cold Spring Harbor Laboratory}},
  doi = {10.1101/2021.08.29.458114},
  abstract = {Evaluating choices in multi-step tasks is thought to involve mentally simulating trajectories. Recent theories propose that the brain simplifies these laborious computations using temporal abstraction: storing actions' consequences, collapsed over multiple timesteps (the Successor Representation; SR). Although predictive neural representations and, separately, behavioral errors ("slips of action") consistent with this mechanism have been reported, it is unknown whether these neural representations support choices in a manner consistent with the SR. We addressed this question by using fMRI to measure predictive representations in a setting where the SR implies specific errors in multi-step expectancies and corresponding behavioral errors. By decoding measures of state predictions from sensory cortex during choice evaluation, we identified evidence that behavioral errors predicted by the SR are accompanied by predictive representations of upcoming task states reflecting SR predicted erroneous multi-step expectancies. These results provide neural evidence for the SR in choice evaluation and contribute toward a mechanistic understanding of flexible and inflexible decision making.},
  chapter = {New Results},
  copyright = {\textcopyright{} 2021, Posted by Cold Spring Harbor Laboratory. This pre-print is available under a Creative Commons License (Attribution-NoDerivs 4.0 International), CC BY-ND 4.0, as described at http://creativecommons.org/licenses/by-nd/4.0/},
  langid = {english},
  file = {/Users/abkara/Dropbox/papers/Russek et al_2021_Neural evidence for the successor representation in choice evaluation.pdf;/Users/abkara/Zotero/storage/A9433DYX/2021.08.29.html}
}

@article{russekPredictiveRepresentationsCan2017,
  title = {Predictive Representations Can Link Model-Based Reinforcement Learning to Model-Free Mechanisms},
  author = {Russek, Evan M. and Momennejad, Ida and Botvinick, Matthew M. and Gershman, Samuel J. and Daw, Nathaniel D.},
  editor = {Daunizeau, Jean},
  year = {2017},
  month = sep,
  journal = {PLOS Computational Biology},
  volume = {13},
  number = {9},
  pages = {e1005768},
  issn = {1553-7358},
  doi = {10.1371/journal.pcbi.1005768},
  langid = {english},
  file = {/Users/abkara/Zotero/storage/7CK4UTL9/Russek et al. - 2017 - Predictive representations can link model-based re.pdf}
}

@misc{russekSelectiveOutcomeReinstatement2021,
  title = {Selective Outcome Reinstatement during Evaluation Drives Heuristics in Risky Choice},
  author = {Russek, Evan and Moran, Rani and Liu, Yunzhe and Dolan, Raymond J. and Huys, Quentin},
  year = {2021},
  month = oct,
  institution = {{PsyArXiv}},
  doi = {10.31234/osf.io/kb6ew},
  abstract = {A ubiquitous feature of human decision making under risk is that individuals differ from each other, as well as from normativity, in how they incorporate reward and probability information. One possible explanation for these deviations is a desire to reduce the number of potential outcomes considered during choice evaluation. Although multiple behavioral models can be invoked involving selective consideration of choice outcomes, whether differences in these tendencies underlie behavioral differences in sensitivity to reward and probability information is unknown. Here we consider neural evidence where we exploit magnetoencephalography (MEG) to decode the actual choice outcomes participants consider when they decide between a gamble and a safe outcome. We show that variability in tendencies of individual participants to reinstate neural outcome representations, based on either their probability or reward, explains variability in the extent to which their choices reflect consideration of probability and reward information. In keeping with this we also show that participants who are higher in behavioral impulsivity fail to preferentially reinstate outcomes with higher probability. Our results suggest that neural differences in the degree to which outcomes are considered shape risk taking strategy, both in decision making tasks, as well as in real life.},
  langid = {american},
  keywords = {Cognitive Neuroscience,Decision Making,Neuroscience,Reactivation,Risk,Simulation},
  file = {/Users/abkara/Dropbox/papers/Russek et al_2021.pdf}
}

@article{schapiroNeuralRepresentationsEvents2013,
  title = {Neural Representations of Events Arise from Temporal Community Structure},
  author = {Schapiro, Anna C and Rogers, Timothy T and Cordova, Natalia I and {Turk-Browne}, Nicholas B and Botvinick, Matthew M},
  year = {2013},
  month = apr,
  journal = {Nature Neuroscience},
  volume = {16},
  number = {4},
  pages = {486--492},
  issn = {1097-6256, 1546-1726},
  doi = {10.1038/nn.3331},
  langid = {english},
  file = {/Users/abkara/Dropbox/papers/Schapiro et al_2013_Neural representations of events arise from temporal community structure.pdf}
}

@article{schlichtingLearningrelatedRepresentationalChanges2015,
  title = {Learning-Related Representational Changes Reveal Dissociable Integration and Separation Signatures in the Hippocampus and Prefrontal Cortex},
  author = {Schlichting, Margaret L. and Mumford, Jeanette A. and Preston, Alison R.},
  year = {2015},
  journal = {Nature Communications},
  volume = {6},
  number = {1},
  doi = {10.1038/ncomms9151},
  file = {/Users/abkara/Dropbox/papers/Schlichting et al_2015_Learning-related representational changes reveal dissociable integration and.pdf}
}

@article{schmidtDisruptingMedialPrefrontal2019a,
  title = {Disrupting the Medial Prefrontal Cortex Alters Hippocampal Sequences during Deliberative Decision Making},
  author = {Schmidt, Brandy and Duin, Anneke A. and Redish, A. David},
  year = {2019},
  month = jun,
  journal = {Journal of Neurophysiology},
  volume = {121},
  number = {6},
  pages = {1981--2000},
  issn = {1522-1598},
  doi = {10.1152/jn.00793.2018},
  abstract = {Current theories of deliberative decision making suggest that deliberative decisions arise from imagined simulations that require interactions between the prefrontal cortex and hippocampus. In rodent navigation experiments, hippocampal theta sequences advance from the location of the rat ahead to the subsequent goal. To examine the role of the medial prefrontal cortex (mPFC) on the hippocampus, we disrupted the mPFC with DREADDs (designer receptors exclusively activated by designer drugs). Using the Restaurant Row foraging task, we found that mPFC disruption resulted in decreased vicarious trial and error behavior, reduced the number of theta sequences, and impaired theta sequences in hippocampus. mPFC disruption led to larger changes in the initiation of the hippocampal theta sequences that represent the current location of the rat rather than to the later portions that represent the future outcomes. These data suggest that the mPFC likely provides an important component to the initiation of deliberative sequences and provides support for an episodic-future thinking, working memory interpretation of deliberation. NEW \& NOTEWORTHY The medial prefrontal cortex (mPFC) and hippocampus interact during deliberative decision making. Disruption of the mPFC impaired hippocampal processes, including the local and nonlocal representations of space along each theta cycle and the initiation of hippocampal theta sequences, while sparing place cell firing characteristics and phase precession. mPFC disruption reduced the deliberative behavioral process vicarious trial and error and improved economic behaviors on this task.},
  langid = {english},
  pmcid = {PMC6620703},
  pmid = {30892976},
  keywords = {Animals,Clozapine,Decision Making,GABA Antagonists,hippocampus,Hippocampus,Neurons,place cell,Prefrontal Cortex,prelimbic cortex,Rats,Serotonin Antagonists,theta,Theta Rhythm,vicarious trial and error},
  file = {/Users/abkara/Zotero/storage/G37SQ6QD/Schmidt et al. - 2019 - Disrupting the medial prefrontal cortex alters hip.pdf}
}

@article{schuckHumanOrbitofrontalCortex2016,
  title = {Human {{Orbitofrontal Cortex Represents}} a {{Cognitive Map}} of {{State Space}}},
  author = {Schuck, Nicolas~W. and Cai, Ming~Bo and Wilson, Robert~C. and Niv, Yael},
  year = {2016},
  month = sep,
  journal = {Neuron},
  volume = {91},
  number = {6},
  pages = {1402--1412},
  issn = {08966273},
  doi = {10.1016/j.neuron.2016.08.019},
  abstract = {Although the orbitofrontal cortex (OFC) has been studied intensely for decades, its precise functions have remained elusive. We recently hypothesized that the OFC contains a ``cognitive map'' of task space in which the current state of the task is represented, and this representation is especially critical for behavior when states are unobservable from sensory input. To test this idea, we apply patternclassification techniques to neuroimaging data from humans performing a decision-making task with 16 states. We show that unobservable task states can be decoded from activity in OFC, and decoding accuracy is related to task performance and the occurrence of individual behavioral errors. Moreover, similarity between the neural representations of consecutive states correlates with behavioral accuracy in corresponding state transitions. These results support the idea that OFC represents a cognitive map of task space and establish the feasibility of decoding state representations in humans using non-invasive neuroimaging.},
  langid = {english},
  file = {/Users/abkara/Dropbox/papers/Schuck et al_2016_Human Orbitofrontal Cortex Represents a Cognitive Map of State Space.pdf;/Users/abkara/Zotero/storage/BKJY5UQ5/S0896627316305116.html}
}

@article{schuckSequentialReplayNonspatial2019,
  title = {Sequential Replay of Nonspatial Task States in the Human Hippocampus},
  author = {Schuck, Nicolas W. and Niv, Yael},
  year = {2019},
  month = jun,
  journal = {Science},
  volume = {364},
  number = {6447},
  pages = {eaaw5181},
  issn = {0036-8075, 1095-9203},
  doi = {10.1126/science.aaw5181},
  abstract = {Sequential neural activity patterns related to spatial experiences are ``replayed'' in the hippocampus of rodents during rest. We investigated whether replay of nonspatial sequences can be detected noninvasively in the human hippocampus. Participants underwent functional magnetic resonance imaging (fMRI) while resting after performing a decision-making task with sequential structure. Hippocampal fMRI patterns recorded at rest reflected sequentiality of previously experienced task states, with consecutive patterns corresponding to nearby states. Hippocampal sequentiality correlated with the fidelity of task representations recorded in the orbitofrontal cortex during decision-making, which were themselves related to better task performance. Our findings suggest that hippocampal replay may be important for building representations of complex, abstract tasks elsewhere in the brain and establish feasibility of investigating fast replay signals with fMRI.},
  langid = {english},
  file = {/Users/abkara/Dropbox/papers/schuck_niv_science_2019.pdf}
}

@misc{smidComputationalBehavioralMarkers2020,
  title = {Computational and {{Behavioral Markers}} of {{Model-based Decision Making}} in {{Childhood}}},
  author = {Smid, Claire Rosalie and Kool, Wouter and Hauser, Tobias U. and Steinbeis, Nikolaus},
  year = {2020},
  month = jan,
  institution = {{PsyArXiv}},
  doi = {10.31234/osf.io/ervsb},
  abstract = {Human decision-making is underpinned by distinct systems that differ in flexibility and associated cognitive cost. A widely accepted dichotomy distinguishes between a cheap but rigid model-free system and a flexible but costly model-based system. Typically, humans use a hybrid of both types of decision-making depending on environmental demands. However, children's use of a model-based system during decision-making has not yet been shown. While prior developmental work has identified simple building blocks of model-based reasoning in young children (1-4 years old), there has been little evidence of this complex cognitive system influencing behavior before adolescence. Here, by using a modified task to make engagement in cognitively costly strategies more rewarding, we show that children aged 5 to 11-years (N = 85), including the youngest children, displayed multiple indicators of model-based decision making, and that the degree of its use increased throughout childhood. Unlike adults (N = 24), however, children did not display adaptive arbitration between model-free and model-based decision making. Our results demonstrate that throughout childhood, children are able to engage in highly sophisticated and costly decision-making strategies. However, the flexible arbitration between decision-making strategies might be a critically late-developing component in human development.},
  langid = {american},
  keywords = {childhood,cognitive neuroscience,Cognitive Neuroscience,cost-benefit arbitration,development,Developmental Psychology,metacontrol,model-based decision-making,model-free decision-making,Neuroscience,reinforcement learning,Social and Behavioral Sciences},
  file = {/Users/abkara/Dropbox/papers/Smid et al_2020.pdf}
}

@article{solwayGoaldirectedDecisionMaking2012,
  title = {Goal-Directed Decision Making as Probabilistic Inference: {{A}} Computational Framework and Potential Neural Correlates},
  shorttitle = {Goal-Directed Decision Making as Probabilistic Inference},
  author = {Solway, Alec and Botvinick, Matthew M.},
  year = {2012},
  journal = {Psychological Review},
  volume = {119},
  number = {1},
  pages = {120--154},
  publisher = {{American Psychological Association}},
  address = {{US}},
  issn = {1939-1471},
  doi = {10.1037/a0026435},
  abstract = {Recent work has given rise to the view that reward-based decision making is governed by two key controllers: a habit system, which stores stimulus\textendash response associations shaped by past reward, and a goal-oriented system that selects actions based on their anticipated outcomes. The current literature provides a rich body of computational theory addressing habit formation, centering on temporal-difference learning mechanisms. Less progress has been made toward formalizing the processes involved in goal-directed decision making. We draw on recent work in cognitive neuroscience, animal conditioning, cognitive and developmental psychology, and machine learning to outline a new theory of goal-directed decision making. Our basic proposal is that the brain, within an identifiable network of cortical and subcortical structures, implements a probabilistic generative model of reward, and that goal-directed decision making is effected through Bayesian inversion of this model. We present a set of simulations implementing the account, which address benchmark behavioral and neuroscientific findings, and give rise to a set of testable predictions. We also discuss the relationship between the proposed framework and other models of decision making, including recent models of perceptual choice, to which our theory bears a direct connection. (PsycINFO Database Record (c) 2016 APA, all rights reserved)},
  keywords = {Cognitive Neuroscience,Decision Making,Inference,Management Planning,Rewards},
  file = {/Users/abkara/Dropbox/papers/Solway_Botvinick_2012_Goal-directed decision making as probabilistic inference.pdf;/Users/abkara/Zotero/storage/AM7BRFBH/2012-00103-002.html}
}

@article{solwayOptimalBehavioralHierarchy2014,
  title = {Optimal {{Behavioral Hierarchy}}},
  author = {Solway, Alec and Diuk, Carlos and C{\'o}rdova, Natalia and Yee, Debbie and Barto, Andrew G. and Niv, Yael and Botvinick, Matthew M.},
  year = {2014},
  month = aug,
  journal = {PLOS Computational Biology},
  volume = {10},
  number = {8},
  pages = {e1003779},
  publisher = {{Public Library of Science}},
  issn = {1553-7358},
  doi = {10.1371/journal.pcbi.1003779},
  abstract = {Human behavior has long been recognized to display hierarchical structure: actions fit together into subtasks, which cohere into extended goal-directed activities. Arranging actions hierarchically has well established benefits, allowing behaviors to be represented efficiently by the brain, and allowing solutions to new tasks to be discovered easily. However, these payoffs depend on the particular way in which actions are organized into a hierarchy, the specific way in which tasks are carved up into subtasks. We provide a mathematical account for what makes some hierarchies better than others, an account that allows an optimal hierarchy to be identified for any set of tasks. We then present results from four behavioral experiments, suggesting that human learners spontaneously discover optimal action hierarchies.},
  langid = {english},
  keywords = {Behavior,Community structure,Human learning,Information theory,Learning,Machine learning,Subroutines,Towns},
  file = {/Users/abkara/Dropbox/papers/Solway et al_2014_Optimal Behavioral Hierarchy.pdf;/Users/abkara/Zotero/storage/RDAHRKU8/article.html}
}

@article{stachenfeldHippocampusPredictiveMap2017,
  title = {The Hippocampus as a Predictive Map},
  author = {Stachenfeld, Kimberly L and Botvinick, Matthew M and Gershman, Samuel J},
  year = {2017},
  month = nov,
  journal = {Nature Neuroscience},
  volume = {20},
  number = {11},
  pages = {1643--1653},
  issn = {1097-6256, 1546-1726},
  doi = {10.1038/nn.4650},
  langid = {english},
  file = {/home/abkara/Dropbox/papers/stachenfeld_et_al_nat_neuro_2017.pdf}
}

@article{suttonDynaIntegratedArchitecture1991,
  title = {Dyna, an Integrated Architecture for Learning, Planning, and Reacting},
  author = {Sutton, Richard S.},
  year = {1991},
  month = jul,
  journal = {ACM SIGART Bulletin},
  volume = {2},
  number = {4},
  pages = {160--163},
  issn = {0163-5719},
  doi = {10.1145/122344.122377},
  abstract = {Dyna is an AI architecture that integrates learning, planning, and reactive execution. Learning methods are used in Dyna both for compiling planning results and for updating a model of the effects of the agent's actions on the world. Planning is incremental and can use the probabilistic and ofttimes incorrect world models generated by learning processes. Execution is fully reactive in the sense that no planning intervenes between perception and action. Dyna relies on machine learning methods for learning from examples---these are among the basic building blocks making up the architecture---yet is not tied to any particular method. This paper briefly introduces Dyna and discusses its strengths and weaknesses with respect to other architectures.},
  file = {/Users/abkara/Zotero/storage/MPFEJWPN/Sutton - 1991 - Dyna, an integrated architecture for learning, pla.pdf}
}

@book{suttonReinforcementLearningIntroduction2018,
  ids = {suttonReinforcementLearningIntroduction2018a},
  title = {Reinforcement Learning: An Introduction},
  shorttitle = {Reinforcement Learning},
  author = {Sutton, Richard S. and Barto, Andrew G.},
  year = {2018},
  series = {Adaptive Computation and Machine Learning Series},
  edition = {Second edition},
  publisher = {{The MIT Press}},
  address = {{Cambridge, Massachusetts}},
  abstract = {"Reinforcement learning, one of the most active research areas in artificial intelligence, is a computational approach to learning whereby an agent tries to maximize the total amount of reward it receives while interacting with a complex, uncertain environment. In Reinforcement Learning, Richard Sutton and Andrew Barto provide a clear and simple account of the field's key ideas and algorithms."--},
  isbn = {978-0-262-03924-6},
  langid = {english},
  lccn = {Q325.6 .R45 2018},
  keywords = {Reinforcement learning},
  file = {/home/abkara/Dropbox/books/RLbook2020.pdf;/home/abkara/Dropbox/books/RLbook2020.pdf;/Users/abkara/Dropbox/books/Sutton and Barto - 2018 - Reinforcement learning an introduction.pdf}
}

@article{tavaresMapSocialNavigation2015,
  title = {A {{Map}} for {{Social Navigation}} in the {{Human Brain}}},
  author = {Tavares, Rita~Morais and Mendelsohn, Avi and Grossman, Yael and Williams, Christian~Hamilton and Shapiro, Matthew and Trope, Yaacov and Schiller, Daniela},
  year = {2015},
  month = jul,
  journal = {Neuron},
  volume = {87},
  number = {1},
  pages = {231--243},
  issn = {08966273},
  doi = {10.1016/j.neuron.2015.06.011},
  abstract = {Deciphering the neural mechanisms of social behavior has propelled the growth of social neuroscience. The exact computations of the social brain, however, remain elusive. Here we investigated how the human brain tracks ongoing changes in social relationships using functional neuroimaging. Participants were lead characters in a role-playing game in which they were to find a new home and a job through interactions with virtual cartoon characters. We found that a twodimensional geometric model of social relationships, a ``social space'' framed by power and affiliation, predicted hippocampal activity. Moreover, participants who reported better social skills showed stronger covariance between hippocampal activity and ``movement'' through ``social space.'' The results suggest that the hippocampus is crucial for social cognition, and imply that beyond framing physical locations, the hippocampus computes a more general, inclusive, abstract, and multidimensional cognitive map consistent with its role in episodic memory.},
  langid = {english},
  keywords = {Cognitive Maps,cool task,Social Maps},
  file = {/Users/abkara/Dropbox/papers/Tavares et al_2015_A Map for Social Navigation in the Human Brain.pdf}
}

@article{thevesHippocampusMapsConcept2020,
  title = {The {{Hippocampus Maps Concept Space}}, {{Not Feature Space}}},
  author = {Theves, Stephanie and Fern{\'a}ndez, Guill{\'e}n and Doeller, Christian F.},
  year = {2020},
  month = sep,
  journal = {Journal of Neuroscience},
  volume = {40},
  number = {38},
  pages = {7318--7325},
  publisher = {{Society for Neuroscience}},
  issn = {0270-6474, 1529-2401},
  doi = {10.1523/JNEUROSCI.0494-20.2020},
  abstract = {The hippocampal formation encodes maps of space and a key question in neuroscience is whether its spatial coding principles also provide a universal metric for the organization of nonspatial, conceptual information. Previous work demonstrated directional coding during navigation through a continuous stimulus feature space as well as mapping of distances in a feature space that was relevant for concept learning. Here we provide the first unambiguous evidence for a hippocampal representation of the actual concept space, by showing that the hippocampal distance signal selectively reflects the mapping of specifically conceptually relevant rather than of all feature dimensions. During fMRI scanning of 32 human participants (21 females), we presented everyday objects, which had beforehand been associated with specific values on three continuous feature dimensions. Crucially, only two dimensions were relevant to prior concept learning. We find that hippocampal responses to the objects reflect their relative distances in a space defined along conceptually relevant dimensions compared with distances in a space defined along all feature dimensions. These findings suggest that the hippocampus supports knowledge acquisition by dynamically encoding information in a space spanned along dimensions that are relevant in relation to define concepts. SIGNIFICANCE STATEMENT How are neural representations of conceptual knowledge organized, such that humans are able to infer never experienced relations or categorize new exemplars? Map-like representations as supported by the hippocampal formation to encode physical space during navigation have been suggested as a suitable format. Here we provide the first evidence for a hippocampal representation of a conceptual space compared with a general feature-based space.},
  chapter = {Research Articles},
  copyright = {Copyright \textcopyright{} 2020 the authors. SfN exclusive license.},
  langid = {english},
  pmid = {32826311},
  keywords = {conceptual knowledge,fMRI,hippocampus,learning,spatial coding},
  file = {/Users/abkara/Dropbox/papers/Theves et al_2020_The Hippocampus Maps Concept Space, Not Feature Space.pdf;/Users/abkara/Zotero/storage/9TIP5WZ3/7318.html}
}

@article{tolmanCognitiveMapsRats1948,
  title = {Cognitive Maps in Rats and Men},
  author = {Tolman, Edward C.},
  year = {1948},
  journal = {Psychological Review},
  volume = {55},
  number = {4},
  pages = {189--208},
  publisher = {{American Psychological Association}},
  address = {{US}},
  issn = {1939-1471(Electronic),0033-295X(Print)},
  doi = {10.1037/h0061626},
  abstract = {This paper is devoted to a description of experiments with rats, mostly at the author's laboratory, and to indicating the significance of these findings on rats for the clinical behavior of men. While all students agree as to the facts reported, they disagree on theory and explanation. 5 kinds of experiments (latent learning, vicarious trial and error, searching for the stimulus, hypotheses, and spatial orientation) are described and discussed. The conditions which favor (cognitive) narrow strip-maps and which favor broad comprehensive maps in rats and in men are considered. Narrow strip-maps seem to be indicated by (1) a damaged brain, (2) an inadequate arrangement of environmentally presented cues, (3) a surplus of repetitions on the original trained-on path, and (4) the presence of too strongly frustrating conditions. The fourth point is elaborated. It is contended that some of the psychological mechanisms which clinical psychologists and other students of personality have uncovered as factors underlying many individual and social maladjustments can be interpreted "as narrowings of our cognitive maps due to too strong motivations or to too intense frustrations." (PsycINFO Database Record (c) 2016 APA, all rights reserved)},
  keywords = {Cognitive Maps,Comparative Psychology,Personality,Rats,Spatial Orientation (Perception)},
  file = {/Users/abkara/Dropbox/papers/Tolman.pdf;/Users/abkara/Zotero/storage/YND2I952/1949-00103-001.html}
}

@article{turk-browneNeuralEvidenceStatistical2009,
  title = {Neural {{Evidence}} of {{Statistical Learning}}: {{Efficient Detection}} of {{Visual Regularities Without Awareness}}},
  shorttitle = {Neural {{Evidence}} of {{Statistical Learning}}},
  author = {{Turk-Browne}, Nicholas B. and Scholl, Brian J. and Chun, Marvin M. and Johnson, Marcia K.},
  year = {2009},
  month = oct,
  journal = {Journal of Cognitive Neuroscience},
  volume = {21},
  number = {10},
  pages = {1934--1945},
  issn = {0898-929X, 1530-8898},
  doi = {10.1162/jocn.2009.21131},
  abstract = {Abstract             Our environment contains regularities distributed in space and time that can be detected by way of statistical learning. This unsupervised learning occurs without intent or awareness, but little is known about how it relates to other types of learning, how it affects perceptual processing, and how quickly it can occur. Here we use fMRI during statistical learning to explore these questions. Participants viewed statistically structured versus unstructured sequences of shapes while performing a task unrelated to the structure. Robust neural responses to statistical structure were observed, and these responses were notable in four ways: First, responses to structure were observed in the striatum and medial temporal lobe, suggesting that statistical learning may be related to other forms of associative learning and relational memory. Second, statistical regularities yielded greater activation in category-specific visual regions (object-selective lateral occipital cortex and word-selective ventral occipito-temporal cortex), demonstrating that these regions are sensitive to information distributed in time. Third, evidence of learning emerged early during familiarization, showing that statistical learning can operate very quickly and with little exposure. Finally, neural signatures of learning were dissociable from subsequent explicit familiarity, suggesting that learning can occur in the absence of awareness. Overall, our findings help elucidate the underlying nature of statistical learning.},
  langid = {english},
  file = {/Users/abkara/Zotero/storage/WSTNFFM7/Turk-Browne et al. - 2009 - Neural Evidence of Statistical Learning Efficient.pdf}
}

@article{vallatPingouinStatisticsPython2018,
  title = {Pingouin: Statistics in {{Python}}},
  shorttitle = {Pingouin},
  author = {Vallat, Raphael},
  year = {2018},
  month = nov,
  journal = {Journal of Open Source Software},
  volume = {3},
  number = {31},
  pages = {1026},
  issn = {2475-9066},
  doi = {10.21105/joss.01026},
  abstract = {Vallat, (2018). Pingouin: statistics in Python. Journal of Open Source Software, 3(31), 1026, https://doi.org/10.21105/joss.01026},
  langid = {english},
  file = {/Users/abkara/Dropbox/papers/Vallat_2018_Pingouin.pdf;/Users/abkara/Zotero/storage/SUWTIFBK/joss.html}
}

@article{vanopheusdenComputationalModelDecision,
  title = {A Computational Model for Decision Tree Search},
  author = {{van Opheusden}, Bas and Galbiati, Gianni and Bnaya, Zahy and Li, Yunqi and Ma, Wei Ji},
  pages = {6},
  abstract = {How do people plan ahead in sequential decision-making tasks? In this article, we compare computational models of human behavior in a challenging variant of tic-tac-toe, to investigate the cognitive processes underlying sequential planning. We validate the most successful model by predicting choices during games, two-alternative forced choices and board evaluations. We then use this model to study individual skill differences, the effects of time pressure and the nature of expertise. Our findings suggest that people perform less tree search under time pressure, and that players search more as they improve during learning.},
  langid = {english},
  file = {/Users/abkara/Zotero/storage/P3LXV4JK/van Opheusden et al. - A computational model for decision tree search.pdf}
}

@article{virtanenSciPyFundamentalAlgorithms2020,
  title = {{{SciPy}} 1.0: Fundamental Algorithms for Scientific Computing in {{Python}}},
  shorttitle = {{{SciPy}} 1.0},
  author = {Virtanen, Pauli and Gommers, Ralf and Oliphant, Travis E. and Haberland, Matt and Reddy, Tyler and Cournapeau, David and Burovski, Evgeni and Peterson, Pearu and Weckesser, Warren and Bright, Jonathan and {van der Walt}, St{\'e}fan J. and Brett, Matthew and Wilson, Joshua and Millman, K. Jarrod and Mayorov, Nikolay and Nelson, Andrew R. J. and Jones, Eric and Kern, Robert and Larson, Eric and Carey, C. J. and Polat, {\.I}lhan and Feng, Yu and Moore, Eric W. and VanderPlas, Jake and Laxalde, Denis and Perktold, Josef and Cimrman, Robert and Henriksen, Ian and Quintero, E. A. and Harris, Charles R. and Archibald, Anne M. and Ribeiro, Ant{\^o}nio H. and Pedregosa, Fabian and {van Mulbregt}, Paul},
  year = {2020},
  month = mar,
  journal = {Nature Methods},
  volume = {17},
  number = {3},
  pages = {261--272},
  publisher = {{Nature Publishing Group}},
  issn = {1548-7105},
  doi = {10.1038/s41592-019-0686-2},
  abstract = {SciPy is an open-source scientific computing library for the Python programming language. Since its initial release in 2001, SciPy has become a de facto standard for leveraging scientific algorithms in Python, with over 600 unique code contributors, thousands of dependent packages, over 100,000 dependent repositories and millions of downloads per year. In this work, we provide an overview of the capabilities and development practices of SciPy 1.0 and highlight some recent technical developments.},
  copyright = {2020 The Author(s)},
  langid = {english},
  keywords = {Biophysical chemistry,Computational biology and bioinformatics,Technology},
  file = {/Users/abkara/Dropbox/papers/Virtanen et al_2020_SciPy 1.pdf;/Users/abkara/Zotero/storage/FWJXDMTB/s41592-019-0686-2.html}
}

@article{wilsonHumansUseDirected2014,
  title = {Humans {{Use Directed}} and {{Random Exploration}} to {{Solve}} the {{Explore}}\textendash{{Exploit Dilemma}}},
  author = {Wilson, Robert C. and Geana, Andra and White, John M. and Ludvig, Elliot A. and Cohen, Jonathan D.},
  year = {2014},
  month = dec,
  journal = {Journal of experimental psychology. General},
  volume = {143},
  number = {6},
  pages = {2074--2081},
  issn = {0096-3445},
  doi = {10.1037/a0038199},
  abstract = {All adaptive organisms face the fundamental tradeoff between pursuing a known reward (exploitation) and sampling lesser-known options in search of something better (exploration). Theory suggests at least two strategies for solving this dilemma: a directed strategy in which choices are explicitly biased toward information seeking, and a random strategy in which decision noise leads to exploration by chance. In this work we investigated the extent to which humans use these two strategies. In our ``Horizon task,'' participants made explore\textendash{} exploit decisions in two contexts that differed in the number of choices that they would make in the future (the time horizon). Participants were allowed to make either a single choice in each game (horizon 1), or 6 sequential choices (horizon 6), giving them more opportunity to explore. By modeling the behavior in these two conditions, we were able to measure exploration-related changes in decision making and quantify the contributions of the two strategies to behavior. We found that participants were more information seeking and had higher decision noise with the longer horizon, suggesting that humans use both strategies to solve the exploration\textendash{} exploitation dilemma. We thus conclude that both information seeking and choice variability can be controlled and put to use in the service of exploration.},
  pmcid = {PMC5635655},
  pmid = {25347535},
  file = {/Users/abkara/Dropbox/papers/Wilson et al_2014_Humans Use Directed and Random Exploration to Solve the Explore–Exploit Dilemma.pdf}
}

@article{wilsonOrbitofrontalCortexCognitive2014,
  title = {Orbitofrontal {{Cortex}} as a {{Cognitive Map}} of {{Task Space}}},
  author = {Wilson, Robert~C. and Takahashi, Yuji~K. and Schoenbaum, Geoffrey and Niv, Yael},
  year = {2014},
  month = jan,
  journal = {Neuron},
  volume = {81},
  number = {2},
  pages = {267--279},
  issn = {0896-6273},
  doi = {10.1016/j.neuron.2013.11.005},
  abstract = {Orbitofrontal cortex (OFC) has long been known to play an important role in decision making. However, the exact nature of that role has remained elusive. Here, we propose a unifying theory of OFC function. We hypothesize that OFC provides an abstraction of currently available information in the form of a labeling of the current task state, which is used for reinforcement learning (RL) elsewhere in the brain. This~function is especially critical when task states include unobservable information, for instance, from working memory. We use this framework to explain classic findings in reversal learning, delayed alternation, extinction, and devaluation as well as more recent findings showing the effect of OFC lesions on the firing of dopaminergic neurons in ventral tegmental area (VTA) in rodents performing an RL task. In addition, we generate a number of testable experimental predictions that can distinguish our theory from other accounts of OFC function.},
  langid = {english},
  file = {/Users/abkara/Dropbox/papers/Wilson et al_2014_Orbitofrontal Cortex as a Cognitive Map of Task Space.pdf;/Users/abkara/Dropbox/papers/Wilson et al_2014_Orbitofrontal Cortex as a Cognitive Map of Task Space2.pdf;/Users/abkara/Dropbox/papers/Wilson et al_2014.pdf;/Users/abkara/Zotero/storage/JBUEG38C/S0896627313010398.html;/Users/abkara/Zotero/storage/WNTH8FBY/S0896627313010398.html}
}


